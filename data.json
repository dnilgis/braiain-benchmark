{
  "last_updated": "2025-12-13 12:55:08 UTC",
  "prompt": "You are tasked with analyzing the evolution of artificial intelligence from 2010 to 2025. Your response must be comprehensive and well-structured.\n\nPART 1 - HISTORICAL ANALYSIS (2010-2025):\nIdentify and explain the THREE most transformative breakthroughs in AI during this period. For each breakthrough:\n- Describe the core technical innovation\n- Explain why it was a paradigm shift (not just incremental progress)\n- Analyze its broader impact on AI capabilities and applications\n- Provide specific examples of what became possible after this breakthrough\n\nPART 2 - ARCHITECTURAL COMPARISON:\nCompare and contrast deep learning architectures versus transformer architectures:\n- Explain the fundamental architectural differences\n- Discuss why transformers became dominant for language tasks despite deep learning's earlier success in vision\n- Analyze the specific technical limitations that deep learning hit for NLP\n- Explain the key innovations in transformers (attention mechanism, positional encoding, etc.) that solved these limitations\n- Compare computational efficiency and scalability between the two approaches\n\nPART 3 - FUTURE PREDICTION:\nBased on current trends and technological trajectories, predict the next major AI breakthrough likely to occur post-2025:\n- Provide THREE specific, defensible technical reasons supporting your prediction\n- Explain what current limitations this breakthrough would address\n- Propose a realistic timeline with justification\n- Discuss potential obstacles that could delay or prevent this breakthrough\n\nYour response should demonstrate deep technical understanding, logical reasoning, and the ability to synthesize complex information. Aim for 2500-3500 characters with clear structure and specific technical details.",
  "max_tokens": 1000,
  "results": [
    {
      "provider": "Groq",
      "model": "llama-3.3-70b-versatile",
      "status": "Online",
      "time": 1.9,
      "ttft": 0.259,
      "tokens_per_second": 383.0,
      "streaming_smoothness": 0,
      "output_tokens": 729,
      "character_count": 2919,
      "cost_per_request": 0.0,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Deep Learning (2010)**: The core technical innovation was the introduction of large-scale neural networks with multiple layers. This was a paradigm shift as it enabled AI to learn complex patterns in data. The impact was significant, with applications in image recognition, speech processing, and natural language processing (NLP). Examples: ImageNet classification, speech recognition in Siri and Google Assistant.\n\n2. **Generative Adversarial Networks (GANs) (2014)**: GANs introduced a new framework for unsupervised learning, enabling AI to generate realistic data. This breakthrough allowed for the creation of realistic images, videos, and music. Examples: AI-generated art, face swapping in videos.\n\n3. **Transformer Architectures (2017)**: The core innovation was the introduction of self-attention mechanisms, enabling AI to process sequential data more efficiently. This was a paradigm shift as it replaced traditional recurrent neural networks (RNNs) for NLP tasks. Examples: BERT, RoBERTa, and other language models that achieved state-of-the-art results in various NLP tasks.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\nDeep learning architectures (e.g., CNNs, RNNs) rely on convolutional and recurrent layers to process data. In contrast, transformer architectures utilize self-attention mechanisms to weigh the importance of different input elements. Transformers became dominant for language tasks due to their ability to handle long-range dependencies and parallelize computation. Deep learning hit limitations in NLP due to the sequential nature of language data, which made RNNs computationally expensive and prone to vanishing gradients. Transformers addressed these limitations through the attention mechanism, positional encoding, and multi-head attention. Transformers are more computationally efficient and scalable than deep learning architectures for NLP tasks.\n\n**PART 3 - FUTURE PREDICTION**\n\nI predict the next major AI breakthrough will be the development of **Explainable AI (XAI) frameworks**. Three technical reasons supporting this prediction:\n\n1. **Model interpretability**: XAI will enable AI models to provide transparent explanations for their decisions.\n2. **Adversarial robustness**: XAI will help develop models that are more resilient to adversarial attacks.\n3. **Human-AI collaboration**: XAI will facilitate more effective human-AI collaboration by providing insights into AI decision-making processes.\n\nThis breakthrough will address current limitations in AI trustworthiness and reliability. I propose a realistic timeline of 5-7 years, justified by the ongoing research in XAI and the increasing demand for transparent AI systems. Potential obstacles include the complexity of developing XAI frameworks that balance interpretability and accuracy, as well as the need for large-scale datasets to train and validate XAI models.",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Deep Learning (2010)**: The core technical innovation was the introduction of large-scale neural networks with multiple layers. This was a paradigm s...",
      "error_info": null
    },
    {
      "provider": "Together AI",
      "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "status": "Online",
      "time": 7.56,
      "ttft": 0.581,
      "tokens_per_second": 175.0,
      "streaming_smoothness": 0,
      "output_tokens": 1323,
      "character_count": 5292,
      "cost_per_request": 0.00155,
      "full_response": "**Part 1 - Historical Analysis (2010-2025)**\n\nThe period from 2010 to 2025 saw significant advancements in artificial intelligence. Three transformative breakthroughs stand out:\n\n### Breakthrough 1: AlexNet (2012)\n\n- **Core Technical Innovation**: AlexNet introduced a deep neural network architecture with ReLU activations, local response normalization, and stochastic gradient descent optimization.\n- **Paradigm Shift**: AlexNet's achievement of a top-5 error rate of 15.3% in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) marked a significant departure from traditional machine learning approaches. This success showcased the potential of deep learning for computer vision tasks.\n- **Broader Impact**: AlexNet's success triggered a surge of interest in deep learning research, leading to significant advancements in image and speech recognition, natural language processing, and other areas. The ImageNet challenge became a benchmark for measuring progress in computer vision.\n- **Examples**: Post-AlexNet, researchers developed and refined deep learning architectures like VGGNet, ResNet, and DenseNet, enabling applications such as image captioning, object detection, and facial recognition.\n\n### Breakthrough 2: Generative Adversarial Networks (GANs) (2014)\n\n- **Core Technical Innovation**: Goodfellow et al. introduced GANs, a framework for unsupervised learning that pits two neural networks against each other in a competitive setting.\n- **Paradigm Shift**: GANs revolutionized the field by enabling the generation of realistic, complex data samples, departing from traditional data-driven approaches.\n- **Broader Impact**: GANs opened up new possibilities for generative modeling, enabling applications like image and video synthesis, text-to-image generation, and style transfer.\n- **Examples**: Post-GAN, researchers developed extensions like Conditional GANs (CGANs), Variational Autoencoders (VAEs), and StyleGAN, enabling data augmentation, image-to-image translation, and realistic image synthesis.\n\n### Breakthrough 3: Transformer Architecture (2017)\n\n- **Core Technical Innovation**: Vaswani et al. introduced the Transformer architecture, which relies on self-attention mechanisms to model long-range dependencies in sequential data.\n- **Paradigm Shift**: The Transformer marked a significant departure from traditional recurrent neural networks (RNNs) and convolutional neural networks (CNNs), offering more efficient and parallelizable computations.\n- **Broader Impact**: The Transformer enabled significant progress in natural language processing (NLP), enabling applications like language translation, text generation, and sentiment analysis.\n- **Examples**: Post-Transformer, researchers developed variants like BERT, RoBERTa, and Transformers-XL, achieving state-of-the-art results in NLP tasks and setting a new standard for pre-training language models.\n\n**Part 2 - Architectural Comparison**\n\n### Deep Learning Architectures vs. Transformer Architectures\n\nDeep learning architectures, built on convolutional and recurrent neural networks, were widely adopted for computer vision and NLP tasks in the early 2010s. However, the Transformer architecture has since become dominant for NLP tasks.\n\n- **Fundamental Architectural Differences**: Deep learning architectures rely on locality and convolutional layers to capture spatial dependencies, whereas the Transformer focuses on sequential dependencies through self-attention mechanisms.\n- **Dominance of Transformers in NLP**: The Transformer architecture addresses specific limitations of deep learning models, including parallelization and the explicit modeling of long-range dependencies.\n- **Technical Limitations of Deep Learning**: Deep learning models struggle with capturing long-range dependencies, requiring careful handling of sequential data through techniques like gradient clipping and regularization.\n- **Innovations in Transformers**: The Transformer's attention mechanism, positional encoding, and multi-head attention allow it to capture long-range dependencies more efficiently.\n- **Computational Efficiency and Scalability**: The Transformer's self-attention mechanism offers better parallelization and computational efficiency compared to deep learning models.\n\n**Part 3 - Future Prediction**\n\n### Next Major AI Breakthrough\n\nBased on current trends and technological trajectories, the next major AI breakthrough is likely to be:\n\n- **Breakthrough**: Development of Robust, Large-Scale Multimodal Pre-Training Models\n\nThree specific technical reasons support this prediction:\n\n1.  **Emerged success of self-supervised pre-training**: Large-scale pre-training models like BERT, RoBERTa, and Generative Pre-Training (GPT) have shown exceptional performance in various NLP tasks, underscoring the effectiveness of self-supervised pre-training.\n2.  **Availability of large multimodal datasets**: The increasing availability of large-scale multimodal datasets, combining text, images, audio, and other data types, creates an opportunity for pre-training models that capture cross-modal relationships.\n3.  **Advances in scalable computational frameworks**: Emerging computational frameworks and optimized hardware (e.g., GPU/TPU) enable large-scale model training, paving the way for",
      "response_preview": "**Part 1 - Historical Analysis (2010-2025)**\n\nThe period from 2010 to 2025 saw significant advancements in artificial intelligence. Three transformative breakthroughs stand out:\n\n### Breakthrough 1: A...",
      "error_info": null
    },
    {
      "provider": "Mistral AI",
      "model": "mistral-large-latest",
      "status": "Online",
      "time": 18.28,
      "ttft": 0.504,
      "tokens_per_second": 51.0,
      "streaming_smoothness": 0,
      "output_tokens": 926,
      "character_count": 3704,
      "cost_per_request": 0.00643,
      "full_response": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. Deep Learning Revolution (2012\u20132015): The Rise of Neural Networks**\n#### **Core Technical Innovation**\nThe breakthrough was the **scalable training of deep neural networks (DNNs)** using:\n- **Convolutional Neural Networks (CNNs)** for image recognition (e.g., AlexNet, 2012)\n- **ReLU activation functions** (faster convergence than sigmoid/tanh)\n- **GPU acceleration** (NVIDIA CUDA, 2007\u20132012) enabling large-scale training\n- **Dropout regularization** (2012) to prevent overfitting\n\n#### **Paradigm Shift**\nBefore 2012, AI relied on **handcrafted feature engineering** (e.g., SIFT, HOG for images) and shallow machine learning models (SVMs, random forests). Deep learning **automated feature extraction**, eliminating the need for domain-specific feature design. This was not just incremental\u2014it was a **fundamental shift from rule-based to data-driven learning**.\n\n#### **Broader Impact**\n- **Computer Vision:** ImageNet accuracy improved from ~75% (2010) to ~95% (2015).\n- **Speech Recognition:** Deep neural networks replaced Gaussian Mixture Models (GMMs), enabling near-human accuracy in systems like Google Voice Search (2012).\n- **Autonomous Systems:** Tesla Autopilot (2014) and Waymo (2016) leveraged CNNs for real-time object detection.\n\n#### **What Became Possible?**\n- **Real-time object detection** (YOLO, 2015)\n- **Medical imaging diagnostics** (e.g., diabetic retinopathy detection, 2016)\n- **Generative models** (Variational Autoencoders, 2013; GANs, 2014)\n\n---\n\n### **2. Transformer Architecture (2017\u20132020): The Foundation of Modern NLP**\n#### **Core Technical Innovation**\nThe **Transformer** (Vaswani et al., 2017) introduced:\n- **Self-attention mechanism** (replacing RNNs/LSTMs) for parallelizable sequence processing\n- **Positional encoding** (to retain word order without recurrence)\n- **Scalable training** (enabled by TPUs and large datasets like Common Crawl)\n\n#### **Paradigm Shift**\nBefore Transformers, **recurrent architectures (RNNs, LSTMs)** dominated NLP but suffered from:\n- **Sequential processing bottlenecks** (slow training)\n- **Vanishing gradients** (poor long-range dependency modeling)\n- **Limited context windows** (struggled with long documents)\n\nTransformers **eliminated recurrence entirely**, enabling **parallel training** and **global context understanding**. This was a **structural revolution**, not just an optimization.\n\n#### **Broader Impact**\n- **Language Models:** BERT (2018) achieved state-of-the-art in 11 NLP tasks (e.g., sentiment analysis, QA).\n- **Multimodal AI:** CLIP (2021) connected text and images via contrastive learning.\n- **Code Generation:** GitHub Copilot (2021) used transformers for autocomplete.\n\n#### **What Became Possible?**\n- **Few-shot learning** (GPT-3, 2020)\n- **Real-time translation** (Google Translate, 2020)\n- **Conversational AI** (ChatGPT, 2022)\n\n---\n\n### **3. Diffusion Models (2020\u20132023): The Generative AI Explosion**\n#### **Core Technical Innovation**\nDiffusion models (Ho et al., 2020) introduced:\n- **Iterative denoising** (gradually refining noise into coherent outputs)\n- **Score-based generative modeling** (leveraging gradient-based optimization)\n- **Latent diffusion** (Stable Diffusion, 2022) for efficient high-resolution generation\n\n#### **Paradigm Shift**\nBefore diffusion, **GANs (2014)** dominated generative AI but suffered from:\n- **Mode collapse** (limited diversity in outputs)\n- **Training instability** (adversarial optimization was fragile)\n- **Poor scalability** (struggled with high-resolution images)\n\nDiff",
      "response_preview": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. Deep Learning Revolu...",
      "error_info": null
    },
    {
      "provider": "OpenAI",
      "model": "gpt-4o-mini",
      "status": "Online",
      "time": 21.47,
      "ttft": 1.223,
      "tokens_per_second": 66.0,
      "streaming_smoothness": 0,
      "output_tokens": 1425,
      "character_count": 5700,
      "cost_per_request": 0.00092,
      "full_response": "# Part 1 - Historical Analysis (2010-2025)\n\n### Breakthrough 1: Deep Learning Revolution (2012)\n**Core Technical Innovation**: The introduction of deep convolutional neural networks (CNNs), with architectures like AlexNet, which utilized multiple layers to learn hierarchical features in data.\n\n**Paradigm Shift**: Prior to this, traditional machine learning methods often relied on handcrafted features and were limited in scalability. Deep learning, particularly CNNs, shifted this paradigm as they enabled automatic feature extraction directly from raw data, drastically improving image classification tasks.\n\n**Broader Impact**: This breakthrough allowed for significant advancements in computer vision, leading to applications such as facial recognition, autonomous vehicles, and enhanced image search capabilities.\n\n**Examples**: Subsequent models like VGG, ResNet, and Inception built on the success of AlexNet, paving the way for real-time image analysis in surveillance systems, medical imaging diagnostics, and smartphone photography enhancements.\n\n### Breakthrough 2: Transformers and NLP Revolution (2017)\n**Core Technical Innovation**: The introduction of the Transformer architecture, particularly through the paper \"Attention is All You Need,\" which utilized self-attention mechanisms and replaced recurrent networks with a feed-forward architecture.\n\n**Paradigm Shift**: Unlike RNNs that processed data sequentially, transformers processed entire sequences simultaneously, allowing for better handling of long-range dependencies. This shift enabled more context-aware language models that could understand subtleties in human language.\n\n**Broader Impact**: Transformers have revolutionized natural language processing (NLP), affecting translation, sentiment analysis, and text generation. The ease of transfer learning with models like BERT and GPT has further democratized access to advanced NLP capabilities.\n\n**Examples**: Applications such as Google Translate and OpenAI's ChatGPT emerged from this advancement, allowing users to interact with AI in a more natural and effective manner.\n\n### Breakthrough 3: Large Language Models and Scalability (2020)\n**Core Technical Innovation**: The emergence of large pre-trained language models (LLMs) like GPT-3, which involved training on vast datasets (hundreds of gigabytes) to generate coherent text and perform numerous tasks.\n\n**Paradigm Shift**: The sheer scale of these models, combined with few-shot and zero-shot learning capabilities, marked a departure from traditional task-specific models and established a framework for generalized AI applications.\n\n**Broader Impact**: This creates substantial advancements in automating content creation, coding, and decision-making processes across various sectors.\n\n**Examples**: LLMs enabled applications in creative writing, coding assistance (e.g., GitHub Copilot), and even personal assistants, showcasing AI's ability to operate effectively in diverse fields without needing extensive retraining.\n\n# Part 2 - Architectural Comparison\n\n### Fundamental Architectural Differences\nDeep learning architectures, especially CNNs, leverage stacked layers that progressively extract features through complex transformations, utilizing local receptive fields and pooling layers. In contrast, transformers utilize attention mechanisms that weigh the relevance of different parts of the input data independently, allowing direct relationships between distant tokens.\n\n### Dominance of Transformers in Language Tasks\nTransformers overtook deep learning's initial success in vision due to their ability to efficiently manage context and dependencies over longer sequences, avoiding the vanishing gradient problems associated with RNNs. They excelled in tasks requiring comprehensive understanding of context and semantics, key in NLP.\n\n### Limitations Faced by Deep Learning in NLP\nDeep learning approaches like RNNs struggled with long-range dependencies due to their sequential nature. This led to difficulties in understanding relationships in long texts and handling context efficiently.\n\n### Keys Innovations in Transformers\n- **Attention Mechanism**: Provides the ability to focus on relevant parts of the input sequence, enabling the model to capture relationships irrespective of the distance between tokens.\n- **Positional Encoding**: Allows the model to understand the sequence order without relying on sequential progression as in RNNs.\n- **Parallelization**: Due to their architecture, transformers facilitate faster training through parallel processing of data.\n\n### Computational Efficiency and Scalability\nTransformers generally allow for better scalability to larger datasets due to their architecture, which facilitates parallelized processing, while deep learning methods often require sequential data handling, slowing training times. The shift to transformer architectures has reduced training time and resource consumption significantly.\n\n# Part 3 - Future Prediction\n\n### Next Major Breakthrough: Generalized AI Models\n**Reasons Supporting Prediction**:\n1. **Integration of Multimodal Learning**: The blending of visual, textual, and auditory data representations is becoming more viable, enhancing the model's common-sense reasoning capabilities.\n2. **Enhanced Efficiency Techniques**: As research progresses on sparse attention mechanisms and efficient transformers, models can become less resource-intensive while retaining or improving their capabilities.\n3. **Improved Transfer Learning**: Advances in transferring knowledge across different domains (e.g., from images to text) will lead to more generalized and robust models that better understand human-like reasoning",
      "response_preview": "# Part 1 - Historical Analysis (2010-2025)\n\n### Breakthrough 1: Deep Learning Revolution (2012)\n**Core Technical Innovation**: The introduction of deep convolutional neural networks (CNNs), with archi...",
      "error_info": null
    },
    {
      "provider": "DeepSeek",
      "model": "deepseek-chat",
      "status": "Online",
      "time": 35.51,
      "ttft": 2.058,
      "tokens_per_second": 35.0,
      "streaming_smoothness": 0,
      "output_tokens": 1245,
      "character_count": 4981,
      "cost_per_request": 0.00041,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning Revolution (2012):** The core innovation was the effective training of deep convolutional neural networks (CNNs) using GPUs, backpropagation, and techniques like ReLU and dropout. This was a paradigm shift because it moved from hand-engineered features to hierarchical, learned feature representations. It enabled superhuman performance in image classification (AlexNet on ImageNet), catalyzing the modern AI boom. Applications like real-time object detection, medical image analysis, and facial recognition became viable.\n\n2.  **Transformer Architecture (2017):** The innovation was the scaled dot-product attention mechanism, which allowed the model to weigh the importance of all parts of an input sequence simultaneously, and positional encoding to inject sequence order. This shifted NLP from sequential processing (RNNs/LSTMs) to parallelizable sequence-to-sequence modeling. It broke the bottleneck of long-range dependencies and enabled massive scaling. This directly led to the era of large language models (BERT, GPT series), making coherent text generation, translation, and code synthesis possible.\n\n3.  **Large Language Model Emergence & Scaling Laws (2020-2022):** The breakthrough was the empirical discovery of predictable scaling laws (by OpenAI, DeepMind) showing that model performance scales predictably with compute, data, and parameter count. This shifted AI development from pure architecture research to a scaling-driven engineering discipline. It enabled the creation of multimodal foundation models (GPT-4, DALL-E 2) with emergent abilities like reasoning, instruction following, and cross-modal understanding, powering applications from AI assistants to generative art.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\n**Fundamental Differences:** Deep learning (specifically CNNs/RNNs) relies on local, hierarchical processing. CNNs use convolutional filters for spatial locality; RNNs process sequences step-by-step, maintaining a hidden state. Transformers use self-attention to compute global dependencies between all tokens in a sequence in a single layer, regardless of distance.\n\n**Dominance in NLP:** While CNNs excelled in vision due to translation invariance and spatial hierarchies, RNNs struggled with NLP's long-range dependencies and were inherently sequential, preventing parallel training. Transformers solved this via parallel self-attention, allowing training on vastly larger datasets.\n\n**Technical Limitations & Transformer Solutions:** RNNs suffered from vanishing gradients and inefficient training. The Transformer's **attention mechanism** directly models relationships between all words, solving the long-range dependency problem. **Positional encodings** provide sequence order information lost in attention. The encoder-decoder framework with masked attention enabled effective sequence generation.\n\n**Efficiency & Scalability:** Transformers are more computationally efficient during training due to parallelization, but their self-attention scales quadratically (\\(O(n^2)\\)) with sequence length, a key limitation. CNNs have linear scaling per layer. However, transformers' scalability with compute and data has proven superior for building general-purpose models, justifying the cost.\n\n**PART 3 - FUTURE PREDICTION**\n\n**Prediction:** The next major breakthrough will be the widespread adoption of **highly sample-efficient, neurosymbolic hybrid architectures** that integrate deep learning's pattern recognition with explicit symbolic reasoning and causal models.\n\n**Supporting Reasons:**\n1.  **Data Exhaustion:** Scaling pure LLMs requires unsustainable data/compute. Future systems must learn from less data via internal reasoning.\n2.  **Causal Understanding:** Current models learn correlations, not cause-effect. Real-world planning and robustness require causal reasoning (e.g., \"if I push this, it will fall\").\n3.  **System 2 Thinking Need:** Models need a \"slow,\" deliberate reasoning loop (like Kahneman's System 2) for complex problem-solving, beyond pattern-matching.\n\n**Limitations Addressed:** This would address poor out-of-distribution generalization, hallucination, inability to perform verifiable logical deduction, and data inefficiency.\n\n**Timeline:** Initial research prototypes will emerge by 2027, with robust frameworks becoming mainstream in AI development by 2030. Justification: Significant academic and corporate (DeepMind, Anthropic) research is already directed at reasoning and hybrid systems.\n\n**Potential Obstacles:**\n*  **Integration Complexity:** Seamlessly blending differentiable (neural) and discrete (symbolic) components is a formidable engineering challenge.\n*  **Scalability:** Maintaining the scalability of pure neural approaches while adding symbolic overhead is non-trivial.\n*  **Defining Primitives:** Determining the optimal set of symbolic primitives or reasoning rules for general intelligence remains an open question.",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning Revolution (2012):** The core innovation was the effective training of deep convolutional neural networks (CNNs) using GPUs, backpropa...",
      "error_info": null
    },
    {
      "provider": "Anthropic",
      "model": "claude-3-5-sonnet-20241022",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-13 12:53:29 UTC"
      }
    },
    {
      "provider": "Google",
      "model": "gemini-1.5-flash",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-13 12:53:36 UTC"
      }
    },
    {
      "provider": "Cohere",
      "model": "command-r-plus",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-13 12:54:06 UTC"
      }
    },
    {
      "provider": "Fireworks",
      "model": "accounts/fireworks/models/llama-v3p1-70b-instruct",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-13 12:54:59 UTC"
      }
    },
    {
      "provider": "Cerebras",
      "model": "llama3.1-70b",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-13 12:55:07 UTC"
      }
    }
  ],
  "history": [
    {
      "timestamp": "2025-12-06 06:39:46 UTC",
      "results": {
        "Groq": {
          "time": 1.67,
          "status": "Online",
          "tokens_per_second": 358.0,
          "ttft": 0.25,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.13,
          "status": "Online",
          "tokens_per_second": 156.0,
          "ttft": 1.956,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.37,
          "status": "Online",
          "tokens_per_second": 54.0,
          "ttft": 0.465,
          "streaming_smoothness": 0.157
        },
        "OpenAI": {
          "time": 21.59,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 2.174,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.05,
          "status": "Online",
          "tokens_per_second": 34.0,
          "ttft": 1.784,
          "streaming_smoothness": 0.028
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-06 12:54:36 UTC",
      "results": {
        "Groq": {
          "time": 1.59,
          "status": "Online",
          "tokens_per_second": 428.0,
          "ttft": 0.195,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.13,
          "status": "Online",
          "tokens_per_second": 141.0,
          "ttft": 2.101,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.86,
          "status": "Online",
          "tokens_per_second": 47.0,
          "ttft": 1.111,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.61,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 1.299,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 37.17,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.431,
          "streaming_smoothness": 0.06
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-06 18:37:29 UTC",
      "results": {
        "Groq": {
          "time": 1.73,
          "status": "Online",
          "tokens_per_second": 328.0,
          "ttft": 0.269,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.3,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.321,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.75,
          "status": "Online",
          "tokens_per_second": 47.0,
          "ttft": 0.937,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.53,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 1.129,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 30.91,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.358,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 02:25:22 UTC",
      "results": {
        "Groq": {
          "time": 1.68,
          "status": "Online",
          "tokens_per_second": 320.0,
          "ttft": 0.199,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.37,
          "status": "Online",
          "tokens_per_second": 115.0,
          "ttft": 0.685,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.59,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.738,
          "streaming_smoothness": 0.192
        },
        "OpenAI": {
          "time": 20.78,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.14,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 36.26,
          "status": "Online",
          "tokens_per_second": 34.0,
          "ttft": 1.497,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 06:39:23 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 336.0,
          "ttft": 0.197,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.86,
          "status": "Online",
          "tokens_per_second": 144.0,
          "ttft": 0.436,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 16.83,
          "status": "Online",
          "tokens_per_second": 80.0,
          "ttft": 1.303,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.56,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 1.576,
          "streaming_smoothness": 0.067
        },
        "DeepSeek": {
          "time": 34.65,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.226,
          "streaming_smoothness": 0.065
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 12:52:59 UTC",
      "results": {
        "Groq": {
          "time": 1.45,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.143,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.81,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.291,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.96,
          "status": "Online",
          "tokens_per_second": 49.0,
          "ttft": 0.471,
          "streaming_smoothness": 0.799
        },
        "OpenAI": {
          "time": 22.43,
          "status": "Online",
          "tokens_per_second": 61.0,
          "ttft": 1.374,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.79,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.366,
          "streaming_smoothness": 0.042
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 18:37:46 UTC",
      "results": {
        "Groq": {
          "time": 1.38,
          "status": "Online",
          "tokens_per_second": 396.0,
          "ttft": 0.158,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 11.08,
          "status": "Online",
          "tokens_per_second": 117.0,
          "ttft": 0.98,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 69.0,
          "ttft": 1.189,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 3.31,
          "streaming_smoothness": 0.241
        },
        "DeepSeek": {
          "time": 33.12,
          "status": "Online",
          "tokens_per_second": 38.0,
          "ttft": 3.082,
          "streaming_smoothness": 0.023
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 02:11:03 UTC",
      "results": {
        "Groq": {
          "time": 1.8,
          "status": "Online",
          "tokens_per_second": 375.0,
          "ttft": 0.266,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.83,
          "status": "Online",
          "tokens_per_second": 173.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.47,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.042,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.16,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 3.077,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.87,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.378,
          "streaming_smoothness": 0.09
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 06:48:36 UTC",
      "results": {
        "Groq": {
          "time": 1.74,
          "status": "Online",
          "tokens_per_second": 377.0,
          "ttft": 0.225,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 13.09,
          "status": "Online",
          "tokens_per_second": 92.0,
          "ttft": 0.437,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.19,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.137,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.39,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 2.397,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.6,
          "status": "Online",
          "tokens_per_second": 30.0,
          "ttft": 1.27,
          "streaming_smoothness": 0.033
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 13:00:14 UTC",
      "results": {
        "Groq": {
          "time": 2.12,
          "status": "Online",
          "tokens_per_second": 347.0,
          "ttft": 0.276,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.36,
          "status": "Online",
          "tokens_per_second": 127.0,
          "ttft": 0.471,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.23,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.478,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 24.11,
          "status": "Online",
          "tokens_per_second": 41.0,
          "ttft": 0.711,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.71,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.107,
          "streaming_smoothness": 0.084
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 18:43:36 UTC",
      "results": {
        "Groq": {
          "time": 1.88,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.49,
          "status": "Online",
          "tokens_per_second": 195.0,
          "ttft": 0.364,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.68,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.341,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.7,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.074,
          "streaming_smoothness": 0.47
        },
        "DeepSeek": {
          "time": 32.09,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 0.935,
          "streaming_smoothness": 0.071
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 02:09:54 UTC",
      "results": {
        "Groq": {
          "time": 1.97,
          "status": "Online",
          "tokens_per_second": 416.0,
          "ttft": 0.198,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.4,
          "status": "Online",
          "tokens_per_second": 143.0,
          "ttft": 0.309,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.03,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 2.049,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.46,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.665,
          "streaming_smoothness": 0.51
        },
        "DeepSeek": {
          "time": 38.93,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.506,
          "streaming_smoothness": 0.021
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 06:45:12 UTC",
      "results": {
        "Groq": {
          "time": 1.66,
          "status": "Online",
          "tokens_per_second": 334.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.28,
          "status": "Online",
          "tokens_per_second": 157.0,
          "ttft": 0.446,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.87,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.486,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 32.11,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 1.192,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 42.03,
          "status": "Online",
          "tokens_per_second": 29.0,
          "ttft": 2.249,
          "streaming_smoothness": 0.061
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 13:02:20 UTC",
      "results": {
        "Groq": {
          "time": 1.69,
          "status": "Online",
          "tokens_per_second": 388.0,
          "ttft": 0.153,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.25,
          "status": "Online",
          "tokens_per_second": 190.0,
          "ttft": 0.35,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.225,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 26.15,
          "status": "Online",
          "tokens_per_second": 37.0,
          "ttft": 3.278,
          "streaming_smoothness": 0.494
        },
        "DeepSeek": {
          "time": 38.27,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.353,
          "streaming_smoothness": 0.037
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 18:39:45 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 365.0,
          "ttft": 0.168,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.55,
          "status": "Online",
          "tokens_per_second": 151.0,
          "ttft": 0.651,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 23.07,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 1.297,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 26.09,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.506,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 31.69,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.187,
          "streaming_smoothness": 0.077
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 02:11:51 UTC",
      "results": {
        "Groq": {
          "time": 1.75,
          "status": "Online",
          "tokens_per_second": 403.0,
          "ttft": 0.366,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.22,
          "status": "Online",
          "tokens_per_second": 207.0,
          "ttft": 0.582,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.95,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 2.078,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 25.37,
          "status": "Online",
          "tokens_per_second": 55.0,
          "ttft": 1.827,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.45,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.231,
          "streaming_smoothness": 0.093
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 06:45:39 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 376.0,
          "ttft": 0.189,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.16,
          "status": "Online",
          "tokens_per_second": 146.0,
          "ttft": 0.333,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.43,
          "status": "Online",
          "tokens_per_second": 50.0,
          "ttft": 1.996,
          "streaming_smoothness": 0.299
        },
        "OpenAI": {
          "time": 26.86,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.981,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.07,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.192,
          "streaming_smoothness": 0.027
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 13:02:42 UTC",
      "results": {
        "Groq": {
          "time": 1.36,
          "status": "Online",
          "tokens_per_second": 325.0,
          "ttft": 0.205,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.29,
          "status": "Online",
          "tokens_per_second": 147.0,
          "ttft": 0.31,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.6,
          "status": "Online",
          "tokens_per_second": 42.0,
          "ttft": 1.082,
          "streaming_smoothness": 0.488
        },
        "OpenAI": {
          "time": 24.1,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.467,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.88,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.121,
          "streaming_smoothness": 0.109
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 18:42:03 UTC",
      "results": {
        "Groq": {
          "time": 1.7,
          "status": "Online",
          "tokens_per_second": 379.0,
          "ttft": 0.269,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.25,
          "status": "Online",
          "tokens_per_second": 178.0,
          "ttft": 0.217,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.84,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 1.331,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.92,
          "status": "Online",
          "tokens_per_second": 48.0,
          "ttft": 0.509,
          "streaming_smoothness": 0.258
        },
        "DeepSeek": {
          "time": 31.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.568,
          "streaming_smoothness": 0.1
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 02:13:30 UTC",
      "results": {
        "Groq": {
          "time": 1.5,
          "status": "Online",
          "tokens_per_second": 380.0,
          "ttft": 0.201,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.78,
          "status": "Online",
          "tokens_per_second": 146.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 18.95,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.227,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.36,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 0.479,
          "streaming_smoothness": 0.496
        },
        "DeepSeek": {
          "time": 39.35,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.931,
          "streaming_smoothness": 0.099
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 06:47:15 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 356.0,
          "ttft": 0.257,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.7,
          "status": "Online",
          "tokens_per_second": 206.0,
          "ttft": 0.307,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 42.0,
          "ttft": 0.509,
          "streaming_smoothness": 0.525
        },
        "OpenAI": {
          "time": 24.47,
          "status": "Online",
          "tokens_per_second": 58.0,
          "ttft": 0.985,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.04,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.5,
          "streaming_smoothness": 0.113
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 13:03:57 UTC",
      "results": {
        "Groq": {
          "time": 1.6,
          "status": "Online",
          "tokens_per_second": 332.0,
          "ttft": 0.298,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.11,
          "status": "Online",
          "tokens_per_second": 152.0,
          "ttft": 0.53,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.29,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.741,
          "streaming_smoothness": 0.691
        },
        "OpenAI": {
          "time": 22.25,
          "status": "Online",
          "tokens_per_second": 62.0,
          "ttft": 1.406,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.62,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.423,
          "streaming_smoothness": 0.093
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 18:42:55 UTC",
      "results": {
        "Groq": {
          "time": 1.35,
          "status": "Online",
          "tokens_per_second": 370.0,
          "ttft": 0.196,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 14.46,
          "status": "Online",
          "tokens_per_second": 91.0,
          "ttft": 0.482,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.23,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.489,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.77,
          "status": "Online",
          "tokens_per_second": 69.0,
          "ttft": 1.935,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 32.35,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.178,
          "streaming_smoothness": 0.006
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 02:13:32 UTC",
      "results": {
        "Groq": {
          "time": 1.67,
          "status": "Online",
          "tokens_per_second": 343.0,
          "ttft": 0.193,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.98,
          "status": "Online",
          "tokens_per_second": 113.0,
          "ttft": 0.698,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.82,
          "status": "Online",
          "tokens_per_second": 56.0,
          "ttft": 0.733,
          "streaming_smoothness": 0.107
        },
        "OpenAI": {
          "time": 20.16,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.33,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.35,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.392,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 06:45:53 UTC",
      "results": {
        "Groq": {
          "time": 1.83,
          "status": "Online",
          "tokens_per_second": 452.0,
          "ttft": 0.205,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.83,
          "status": "Online",
          "tokens_per_second": 162.0,
          "ttft": 0.603,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.15,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.673,
          "streaming_smoothness": 0.26
        },
        "OpenAI": {
          "time": 27.03,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 1.562,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.38,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.421,
          "streaming_smoothness": 0.045
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 13:00:50 UTC",
      "results": {
        "Groq": {
          "time": 1.77,
          "status": "Online",
          "tokens_per_second": 423.0,
          "ttft": 0.186,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.7,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.41,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.84,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 1.433,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 24.34,
          "status": "Online",
          "tokens_per_second": 38.0,
          "ttft": 0.747,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 37.37,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.349,
          "streaming_smoothness": 0.121
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 18:42:55 UTC",
      "results": {
        "Groq": {
          "time": 1.64,
          "status": "Online",
          "tokens_per_second": 363.0,
          "ttft": 0.129,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.92,
          "status": "Online",
          "tokens_per_second": 148.0,
          "ttft": 0.468,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.48,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 0.49,
          "streaming_smoothness": 0.041
        },
        "OpenAI": {
          "time": 23.98,
          "status": "Online",
          "tokens_per_second": 58.0,
          "ttft": 1.461,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 31.27,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.173,
          "streaming_smoothness": 0.096
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 02:06:27 UTC",
      "results": {
        "Groq": {
          "time": 1.81,
          "status": "Online",
          "tokens_per_second": 352.0,
          "ttft": 0.28,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 13.11,
          "status": "Online",
          "tokens_per_second": 136.0,
          "ttft": 0.466,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.85,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.757,
          "streaming_smoothness": 0.299
        },
        "OpenAI": {
          "time": 26.05,
          "status": "Online",
          "tokens_per_second": 52.0,
          "ttft": 1.229,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 36.91,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.277,
          "streaming_smoothness": 0.017
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 06:41:23 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 340.0,
          "ttft": 0.155,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.27,
          "status": "Online",
          "tokens_per_second": 148.0,
          "ttft": 0.304,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.18,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 0.444,
          "streaming_smoothness": 0.303
        },
        "OpenAI": {
          "time": 20.83,
          "status": "Online",
          "tokens_per_second": 66.0,
          "ttft": 1.398,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.67,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.269,
          "streaming_smoothness": 0.002
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 12:55:08 UTC",
      "results": {
        "Groq": {
          "time": 1.9,
          "status": "Online",
          "tokens_per_second": 383.0,
          "ttft": 0.259,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.56,
          "status": "Online",
          "tokens_per_second": 175.0,
          "ttft": 0.581,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.28,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.504,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.47,
          "status": "Online",
          "tokens_per_second": 66.0,
          "ttft": 1.223,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.51,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 2.058,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    }
  ],
  "reliability_scores": {
    "Groq": 100.0,
    "Together AI": 100.0,
    "Mistral AI": 100.0,
    "OpenAI": 100.0,
    "DeepSeek": 100.0,
    "Anthropic": 0.0,
    "Google": 0.0,
    "Cohere": 0.0,
    "Fireworks": 0.0,
    "Cerebras": 0.0
  },
  "metadata": {
    "version": "3.0",
    "parallel_testing": false,
    "streaming_enabled": true,
    "timeout": 90,
    "retries": 3
  }
}