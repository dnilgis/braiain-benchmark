{
  "last_updated": "2025-12-13 18:37:33 UTC",
  "prompt": "You are tasked with analyzing the evolution of artificial intelligence from 2010 to 2025. Your response must be comprehensive and well-structured.\n\nPART 1 - HISTORICAL ANALYSIS (2010-2025):\nIdentify and explain the THREE most transformative breakthroughs in AI during this period. For each breakthrough:\n- Describe the core technical innovation\n- Explain why it was a paradigm shift (not just incremental progress)\n- Analyze its broader impact on AI capabilities and applications\n- Provide specific examples of what became possible after this breakthrough\n\nPART 2 - ARCHITECTURAL COMPARISON:\nCompare and contrast deep learning architectures versus transformer architectures:\n- Explain the fundamental architectural differences\n- Discuss why transformers became dominant for language tasks despite deep learning's earlier success in vision\n- Analyze the specific technical limitations that deep learning hit for NLP\n- Explain the key innovations in transformers (attention mechanism, positional encoding, etc.) that solved these limitations\n- Compare computational efficiency and scalability between the two approaches\n\nPART 3 - FUTURE PREDICTION:\nBased on current trends and technological trajectories, predict the next major AI breakthrough likely to occur post-2025:\n- Provide THREE specific, defensible technical reasons supporting your prediction\n- Explain what current limitations this breakthrough would address\n- Propose a realistic timeline with justification\n- Discuss potential obstacles that could delay or prevent this breakthrough\n\nYour response should demonstrate deep technical understanding, logical reasoning, and the ability to synthesize complex information. Aim for 2500-3500 characters with clear structure and specific technical details.",
  "max_tokens": 1000,
  "results": [
    {
      "provider": "Groq",
      "model": "llama-3.3-70b-versatile",
      "status": "Online",
      "time": 1.86,
      "ttft": 0.2,
      "tokens_per_second": 347.0,
      "streaming_smoothness": 0,
      "output_tokens": 646,
      "character_count": 2587,
      "cost_per_request": 0.0,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Deep Learning (2010)**: Core innovation was the use of convolutional neural networks (CNNs) and recurrent neural networks (RNNs). This was a paradigm shift as it enabled learning from large amounts of data, surpassing traditional machine learning methods. Impact: Image recognition, speech recognition, and natural language processing (NLP) capabilities improved significantly. Example: Google's self-driving cars became possible due to deep learning's ability to process visual data.\n\n2. **Generative Adversarial Networks (GANs) (2014)**: Core innovation was the introduction of a generator and discriminator network that competed to improve each other. Paradigm shift: GANs enabled the generation of realistic synthetic data, revolutionizing fields like computer vision and NLP. Impact: Synthetic data generation, style transfer, and data augmentation became possible. Example: Deepfakes, AI-generated music, and art.\n\n3. **Transformers (2017)**: Core innovation was the self-attention mechanism, allowing models to weigh the importance of different input elements. Paradigm shift: Transformers enabled efficient processing of sequential data, especially for NLP tasks. Impact: State-of-the-art results in machine translation, text classification, and question-answering. Example: BERT, RoBERTa, and other transformer-based models achieved unparalleled performance in NLP tasks.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\nDeep learning architectures (CNNs, RNNs) relied on convolutional and recurrent layers, whereas transformers used self-attention mechanisms. Transformers dominated language tasks due to their ability to model complex dependencies and relationships in sequential data. Deep learning hit limitations in NLP, such as fixed context windows and lack of parallelization. Transformers solved these with attention mechanisms, positional encoding, and multi-head attention. Transformers are more computationally efficient and scalable than deep learning architectures for NLP tasks.\n\n**PART 3 - FUTURE PREDICTION**\n\nNext major AI breakthrough: **Explainable AI (XAI)**. Technical reasons: (1) increasing demand for transparency, (2) advancements in attention mechanisms, and (3) growing need for model interpretability. XAI would address current limitations in model explainability, trustworthiness, and reliability. Timeline: 2028-2030, justified by current research momentum and industry demand. Obstacles: complexity of neural networks, lack of standard evaluation metrics, and balancing interpretability with performance.",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Deep Learning (2010)**: Core innovation was the use of convolutional neural networks (CNNs) and recurrent neural networks (RNNs). This was a paradigm...",
      "error_info": null
    },
    {
      "provider": "Together AI",
      "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "status": "Online",
      "time": 8.25,
      "ttft": 0.457,
      "tokens_per_second": 147.0,
      "streaming_smoothness": 0,
      "output_tokens": 1215,
      "character_count": 4862,
      "cost_per_request": 0.00146,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Convolutional Neural Networks (CNNs)**: The core technical innovation in CNNs is the use of convolutional and pooling layers that enable local feature extraction and invariance to small transformations. This breakthrough was a paradigm shift as it allowed for automatic feature learning, surpassing traditional computer vision techniques relying on manual feature engineering. As a result, the 2012 ImageNet Large Scale Visual Recognition Challenge winner (AlexNet) achieved a significant reduction in error rate, from 26.7% to 15.3%, which demonstrates the profound impact on AI capabilities and applications. Examples of what became possible after this breakthrough include self-driving cars, facial recognition systems, and medical image analysis.\n\n2. **Generative Adversarial Networks (GANs)**: GANs introduced the concept of adversarial training, where a generator model produces samples while a discriminator evaluates their authenticity. This breakthrough revolutionized areas such as computer-generated imagery, synthetic data creation, and anomaly detection. With the ability to generate realistic data samples, researchers have been able to significantly augment limited datasets and accelerate development. This led to the creation of realistic deepfakes and AI-powered image, video, and audio content creation tools.\n\n3. **Transformer Architectures**: The Transformer model, introduced in 2017, utilized self-attention mechanisms to allow the model to weigh the importance of each input element relative to others. This breakthrough overcame the limitations of traditional Recurrent Neural Networks (RNNs) for Natural Language Processing (NLP) tasks, enabling improvements in long-range dependencies and parallelization. As a result, AI-powered language translation systems and question-answering models experienced substantial improvements.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\nDeep learning architectures (CNNs, RNNs) relied on localized feature extraction and sequential processing, often leading to difficulties in modeling complex long-range dependencies in NLP tasks. In contrast, transformer architectures introduced self-attention mechanisms and positional encoding to solve these limitations. The key innovations in transformers include:\n\n* The self-attention mechanism, which enabled efficient modeling of long-range dependencies\n* Positional encoding, which introduced sequential information into the model\n* Multi-head attention, which allowed the model to jointly attend to information from different representation subspaces\n\nTransformers have become dominant for NLP tasks, offering significant performance improvements and efficiency gains. They enable parallelization, unlike traditional RNNs, and allow for larger models that better capture complex relationships in the data.\n\n**PART 3 - FUTURE PREDICTION**\n\nNext major AI breakthrough: **Cognitive Graph Networks (CGNs)**\n\nI predict the development of Cognitive Graph Networks that integrate knowledge graphs with probabilistic reasoning, enabling more ef\ufb01cient and efficacious decision-making, particularly in areas with limited data and potential long-tailed distributions.\n\nTechnical reasons supporting this prediction:\n1. **Rise of Explainable AI**: CGNs can learn interpretable models that respect domain knowledge.\n2. **Recent Advances in Graph Neural Networks (GNNs)**: Successful GNN applications in various domains have laid the groundwork for more sophisticated knowledge-centric models.\n3. **Neural Symbolic Reasoning**: CGNs have the potential to integrate symbolic reasoning with neural networks for more comprehensive and intuitive decision-making.\n\nThis breakthrough would address current limitations:\n- **Lack of Interpretable Models**: Explainability will be an essential feature of CGNs.\n- **Handling Uncertainty**: Probabilistic foundations of CGNs will enable ef\ufb01cient handling of uncertainty.\n- **Limited Knowledge Representation**: Integrated knowledge graphs will enrich representations and decision-making.\n\nRealistic timeline: 2028-2032 (multiple research milestones and collaborative efforts necessary for this breakthrough)\n\nObstacles that could delay or prevent this breakthrough:\n- **Training large CGNs**: Risk of gigantic model capacities and related resource consumption issues.\n- **Explainability Evaluation**: Standardized metrics for interpretable AI evaluation need to be developed to efficiently estimate CGN efficacy.\n\nThe ongoing advancements and the connections between knowledge representation, symbolic reasoning, and neural networks make the emergence of Cognitive Graph Networks an appealing prediction, answering some of AI's ongoing fundamental technical issues, despite the essential complexities that the research community must overcome before potential release into production.",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Convolutional Neural Networks (CNNs)**: The core technical innovation in CNNs is the use of convolutional and pooling layers that enable local featur...",
      "error_info": null
    },
    {
      "provider": "OpenAI",
      "model": "gpt-4o-mini",
      "status": "Online",
      "time": 16.28,
      "ttft": 1.146,
      "tokens_per_second": 82.0,
      "streaming_smoothness": 0,
      "output_tokens": 1340,
      "character_count": 5363,
      "cost_per_request": 0.00087,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n**1. Breakthrough: Deep Learning**\n- **Core Technical Innovation**: The introduction of deep learning, particularly through advancements in convolutional neural networks (CNNs), allowed for hierarchical learning of features from raw data.\n- **Paradigm Shift**: This was not merely a refinement but a foundational shift; deep learning enabled computers to surpass human performance in various tasks, such as image recognition, with systems like AlexNet demonstrating dramatic accuracy improvements.\n- **Broader Impact on AI Capabilities**: Deep learning transformed fields such as computer vision, speech recognition, and automation. Applications transitioned from rule-based systems to models capable of learning from vast datasets.\n- **Examples of New Possibilities**: The success of systems like Google Photos in image classification, automated translations via Google Translate, and advancements in autonomous driving by companies like Tesla all stemmed from deep learning innovations.\n\n**2. Breakthrough: Reinforcement Learning (RL)**\n- **Core Technical Innovation**: Reinforcement Learning frameworks achieved significant advancements, particularly through algorithms like Deep Q-Networks (DQN) and Proximal Policy Optimization (PPO).\n- **Paradigm Shift**: This approach allowed AI to make decisions by learning through trial and error, rather than being explicitly programmed, thus enabling it to perform complex tasks such as game playing and robotics.\n- **Broader Impact on AI Capabilities**: RL fueled the development of AI that could adapt to dynamic environments, leading to applications in robotics, game development, and automated decision systems.\n- **Examples of New Possibilities**: Notably, the victory of DeepMind's AlphaGo over a human world champion and advances in robotic manipulation and navigation tasks showcased the capabilities of RL.\n\n**3. Breakthrough: Transformer Architecture**\n- **Core Technical Innovation**: The transformer model, introduced in 2017, utilized self-attention mechanisms to process sequential data without being constrained by the limitations of recurrent networks.\n- **Paradigm Shift**: Transformative in nature, transformers fundamentally changed how tasks involving language processing and understanding were approached, enabling models to capture complex contextual relationships.\n- **Broader Impact on AI Capabilities**: This innovation led to more effective natural language processing (NLP) and understanding, providing tools for a range of applications from chatbots to translation engines.\n- **Examples of New Possibilities**: The rise of models like BERT, GPT-3, and T5 demonstrated the capability of transformers to achieve state-of-the-art results in numerous NLP tasks including sentiment analysis and coherent text generation.\n\n---\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\n**1. Fundamental Architectural Differences**:\n- **Deep Learning Architectures**: Based on a feedforward structure, especially CNNs for images and recurrent neural networks (RNNs) for sequences, which process data sequentially.\n- **Transformer Architectures**: Utilize a self-attention mechanism to weigh the significance of different parts of the input data simultaneously, allowing for parallel processing and richer context extraction.\n\n**2. Dominance of Transformers in Language Tasks**:\n- Despite the initial success of deep learning in computer vision, RNN-based architectures struggled with long-term dependencies in NLP due to vanishing gradients and sequential processing limitations.\n- Transformers addressed these issues, allowing models to consider the entire context of input data rather than relying on a fixed window of information.\n\n**3. Technical Limitations of Deep Learning for NLP**:\n- RNNs had difficulty scaling with long sequences, struggled with memory retention over time, and faced inefficiencies related to sequential processing.\n  \n**4. Key Innovations in Transformers**:\n- **Attention Mechanism**: Enabled the model to focus selectively on relevant parts of the input data.\n- **Positional Encoding**: Facilitated contextual understanding by encoding the order of words in sequences, which is essential for language structure.\n\n**5. Computational Efficiency and Scalability**:\n- Transformers allow for significantly quicker training times because they leverage parallel computation, making them more efficient for handling large datasets compared to the sequential training of RNNs.\n- This efficiency also affords transformers scalability, where adding layers and parameters continues to yield performance improvements without the diminishing returns seen in earlier architectures.\n\n---\n\n**PART 3 - FUTURE PREDICTION**\n\n**Prediction: Emergence of Generalized AI Systems**\n- **Technical Reasons Supporting Prediction**:\n  1. **Integration of Multimodal Learning**: Progress in systems that leverage varying types of data (visual, auditory, linguistic) will provide richer context and understanding.\n  2. **Self-supervised Learning**: Developments in unsupervised and self-supervised models will reduce the dependency on labeled datasets, making AI learning more rapid and widespread.\n  3. **Neurosymbolic Approaches**: Combining neural networks with symbolic reasoning could enable more complex decision-making processes akin to human reasoning.\n\n- **Limit",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n**1. Breakthrough: Deep Learning**\n- **Core Technical Innovation**: The introduction of deep learning, particularly through advancements in convolutional ...",
      "error_info": null
    },
    {
      "provider": "Mistral AI",
      "model": "mistral-large-latest",
      "status": "Online",
      "time": 17.75,
      "ttft": 0.689,
      "tokens_per_second": 53.0,
      "streaming_smoothness": 0.135,
      "output_tokens": 937,
      "character_count": 3750,
      "cost_per_request": 0.0065,
      "full_response": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. Deep Learning Revolution (2012\u20132015): The Rise of Neural Networks**\n#### **Core Technical Innovation**\nThe breakthrough was the **scalable training of deep neural networks (DNNs)**, particularly **convolutional neural networks (CNNs)**, on large datasets using **GPU acceleration**. Key milestones:\n- **AlexNet (2012)**: A deep CNN trained on ImageNet, achieving a **15.3% error rate** (vs. 26.2% for traditional methods), demonstrating that depth and computational power could outperform hand-engineered features.\n- **Dropout (2012)**: A regularization technique to prevent overfitting in deep networks.\n- **ReLU activation (2011)**: Replaced sigmoid/tanh, mitigating the vanishing gradient problem.\n\n#### **Paradigm Shift**\nBefore 2012, AI relied on **feature engineering** (e.g., SIFT, HOG) and shallow models (SVMs, decision trees). Deep learning **automated feature extraction**, eliminating the need for manual design. This was not just incremental\u2014it was a **fundamental shift from rule-based to data-driven learning**.\n\n#### **Broader Impact**\n- **Computer Vision**: Enabled **real-time object detection** (YOLO, 2015), **facial recognition** (DeepFace, 2014), and **medical imaging** (e.g., detecting tumors in X-rays).\n- **Speech Recognition**: Google\u2019s **WaveNet (2016)** and **Deep Speech (2014)** improved accuracy by **~50%** over traditional HMMs.\n- **Autonomous Systems**: Tesla\u2019s Autopilot (2014) and Waymo\u2019s self-driving cars leveraged CNNs for perception.\n\n#### **What Became Possible?**\n- **ImageNet-scale classification** (1,000+ categories with human-level accuracy).\n- **End-to-end learning** (e.g., AlphaGo, 2016, which beat a world champion in Go).\n- **Transfer learning** (pre-trained models like VGG, ResNet could be fine-tuned for new tasks).\n\n---\n\n### **2. Transformer Architecture (2017\u20132020): The Foundation of Modern NLP**\n#### **Core Technical Innovation**\n**Attention Is All You Need (Vaswani et al., 2017)** introduced the **Transformer**, replacing recurrent (RNN/LSTM) and convolutional (CNN) architectures with:\n- **Self-attention mechanism**: Computes relationships between all tokens in parallel, enabling **long-range dependency modeling**.\n- **Positional encoding**: Injects sequence order information without recurrence.\n- **Multi-head attention**: Allows the model to focus on different parts of the input simultaneously.\n\n#### **Paradigm Shift**\nBefore Transformers, NLP relied on **RNNs/LSTMs**, which suffered from:\n- **Sequential processing** (slow training, no parallelization).\n- **Vanishing gradients** (struggled with long sequences).\n- **Fixed-length context windows** (limited memory).\n\nTransformers **eliminated recurrence entirely**, enabling:\n- **Parallel training** (scalable to massive datasets).\n- **Global context understanding** (e.g., BERT\u2019s bidirectional attention).\n- **Zero-shot and few-shot learning** (e.g., GPT-3\u2019s in-context learning).\n\n#### **Broader Impact**\n- **Language Models**: BERT (2018) achieved **state-of-the-art in 11 NLP tasks** (e.g., SQuAD, GLUE). GPT-3 (2020) demonstrated **few-shot learning** (writing code, essays, chatbots).\n- **Multimodal AI**: CLIP (2021) and DALL-E (2021) combined vision and language via Transformers.\n- **Efficiency Gains**: Reduced training time from **weeks (RNNs) to days (Transformers)**.\n\n#### **What Became Possible?**\n- **Conversational AI** (e.g., ChatGPT, 2022).\n- **Code generation** (GitHub Copilot, 2021).\n- **Real-time translation** (Google Translate, 2020).\n- **Automated content creation** (e.g., AI-generated art, music, video).\n\n---\n\n### **3",
      "response_preview": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. Deep Learning Revolu...",
      "error_info": null
    },
    {
      "provider": "DeepSeek",
      "model": "deepseek-chat",
      "status": "Online",
      "time": 31.38,
      "ttft": 1.383,
      "tokens_per_second": 39.0,
      "streaming_smoothness": 0.102,
      "output_tokens": 1229,
      "character_count": 4917,
      "cost_per_request": 0.00041,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning Revolution (c. 2012):**\n    *   **Core Innovation:** The effective training of very deep convolutional neural networks (CNNs) using GPUs, backpropagation, and techniques like ReLU and Dropout.\n    *   **Paradigm Shift:** Moved AI from hand-engineered feature extraction to end-to-end learned feature hierarchies. It proved that scaling neural networks with data and compute yielded qualitatively better performance.\n    *   **Impact & Example:** Enabled superhuman performance in image classification (AlexNet on ImageNet). This breakthrough directly catalyzed the modern AI era, making perception tasks (vision, speech) a solved commodity and enabling applications from medical imaging to autonomous vehicle perception.\n\n2.  **Transformer Architecture (2017):**\n    *   **Core Innovation:** The \"attention is all you need\" mechanism, which replaced recurrent (RNN) and convolutional operations for sequence modeling with self-attention and positional encoding.\n    *   **Paradigm Shift:** It decoupled sequential computation from modeling dependencies, allowing for massive parallelization during training and modeling very long-range dependencies regardless of distance in the sequence.\n    *   **Impact & Example:** It became the foundational architecture for large language models (LLMs). It made training on internet-scale text corpora feasible, leading directly to GPT and BERT families. This enabled coherent long-form text generation, context-aware translation, and zero-shot task generalization.\n\n3.  **Scaled Multimodal Foundation Models (c. 2020-2024):**\n    *   **Core Innovation:** Scaling transformer-based architectures to hundreds of billions of parameters and training them on massive, aligned multimodal datasets (text, image, code).\n    *   **Paradigm Shift:** Moved from narrow, single-task models to general-purpose \"reasoning engines.\" Emergent abilities like in-context learning and chain-of-thought reasoning appeared at scale.\n    *   **Impact & Example:** Models like GPT-4, Claude, and DALL-E 2/3 demonstrated capabilities across domains without task-specific fine-tuning. This enabled AI assistants, advanced code generation, and creative co-pilots, shifting the industry focus from model building to prompting and steering.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\n*   **Fundamental Differences:** Classic **deep learning (CNNs/RNNs)** uses local, inductive biases: CNNs assume spatial locality via convolutions; RNNs assume temporal sequence via recurrence. **Transformers** use self-attention to compute pairwise relationships between all elements in a set, creating a fully connected interaction graph. They have no inherent notion of order, requiring explicit **positional encoding**.\n*   **Dominance in NLP:** CNNs excelled in vision due to translation invariance. RNNs, the pre-transformer NLP workhorse, suffered from vanishing gradients and sequential processing, making them slow to train and poor at modeling long-range context. This was the key **technical limitation**.\n*   **Transformer Innovations:** The **self-attention mechanism** solved the long-range dependency problem by allowing direct token-to-token interaction. Combined with **positional encoding**, it provided sequence order. This enabled full parallelization of training (unlike RNNs), dramatically improving computational efficiency on hardware like TPU/GPU pods.\n*   **Efficiency & Scalability:** For a given task, CNNs/RNNs can be more parameter-efficient. However, transformers scale predictably and vastly better with increased data and compute. Their parallelizable nature makes them ideal for the largest supercomputers, leading to the \"scaling laws\" paradigm. Their computational cost scales quadratically with sequence length (a key downside), but this is offset by their training efficiency and performance gains.\n\n**PART 3 - FUTURE PREDICTION**\n\n*   **Prediction:** The next major breakthrough will be the widespread adoption of **highly sample-efficient, planning-based AI systems** that reliably decompose and execute complex, multi-step tasks in dynamic environments (e.g., \"design and deploy a website\" or \"conduct a multi-tool scientific experiment\").\n*   **Supporting Reasons:**\n    1.  **Architectural Maturation:** Current LLMs are brilliant \"associative engines\" but poor at deliberate, hierarchical planning. Research into \"System 2\" cognitive architectures, LLM-based verifiers, and search-integrated models (like AlphaCode 2) is rapidly advancing.\n    2.  **Economic Imperative:** The high cost of inference for massive models creates demand for systems that get things right in fewer, more reasoned steps.\n    3.  **Robotics & Embodiment Drive:** Real-world AI agents require robust planning and state tracking. Advances in simulation and transfer learning are creating the training grounds for these capabilities.\n*   **",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning Revolution (c. 2012):**\n    *   **Core Innovation:** The effective training of very deep convolutional neural networks (CNNs) using GP...",
      "error_info": null
    },
    {
      "provider": "Anthropic",
      "model": "claude-3-5-sonnet-20241022",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-13 18:35:59 UTC"
      }
    },
    {
      "provider": "Google",
      "model": "gemini-1.5-flash",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-13 18:36:06 UTC"
      }
    },
    {
      "provider": "Cohere",
      "model": "command-r-plus",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-13 18:36:35 UTC"
      }
    },
    {
      "provider": "Fireworks",
      "model": "accounts/fireworks/models/llama-v3p1-70b-instruct",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-13 18:37:24 UTC"
      }
    },
    {
      "provider": "Cerebras",
      "model": "llama3.1-70b",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-13 18:37:32 UTC"
      }
    }
  ],
  "history": [
    {
      "timestamp": "2025-12-06 12:54:36 UTC",
      "results": {
        "Groq": {
          "time": 1.59,
          "status": "Online",
          "tokens_per_second": 428.0,
          "ttft": 0.195,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.13,
          "status": "Online",
          "tokens_per_second": 141.0,
          "ttft": 2.101,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.86,
          "status": "Online",
          "tokens_per_second": 47.0,
          "ttft": 1.111,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.61,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 1.299,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 37.17,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.431,
          "streaming_smoothness": 0.06
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-06 18:37:29 UTC",
      "results": {
        "Groq": {
          "time": 1.73,
          "status": "Online",
          "tokens_per_second": 328.0,
          "ttft": 0.269,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.3,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.321,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.75,
          "status": "Online",
          "tokens_per_second": 47.0,
          "ttft": 0.937,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.53,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 1.129,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 30.91,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.358,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 02:25:22 UTC",
      "results": {
        "Groq": {
          "time": 1.68,
          "status": "Online",
          "tokens_per_second": 320.0,
          "ttft": 0.199,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.37,
          "status": "Online",
          "tokens_per_second": 115.0,
          "ttft": 0.685,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.59,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.738,
          "streaming_smoothness": 0.192
        },
        "OpenAI": {
          "time": 20.78,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.14,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 36.26,
          "status": "Online",
          "tokens_per_second": 34.0,
          "ttft": 1.497,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 06:39:23 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 336.0,
          "ttft": 0.197,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.86,
          "status": "Online",
          "tokens_per_second": 144.0,
          "ttft": 0.436,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 16.83,
          "status": "Online",
          "tokens_per_second": 80.0,
          "ttft": 1.303,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.56,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 1.576,
          "streaming_smoothness": 0.067
        },
        "DeepSeek": {
          "time": 34.65,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.226,
          "streaming_smoothness": 0.065
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 12:52:59 UTC",
      "results": {
        "Groq": {
          "time": 1.45,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.143,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.81,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.291,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.96,
          "status": "Online",
          "tokens_per_second": 49.0,
          "ttft": 0.471,
          "streaming_smoothness": 0.799
        },
        "OpenAI": {
          "time": 22.43,
          "status": "Online",
          "tokens_per_second": 61.0,
          "ttft": 1.374,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.79,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.366,
          "streaming_smoothness": 0.042
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 18:37:46 UTC",
      "results": {
        "Groq": {
          "time": 1.38,
          "status": "Online",
          "tokens_per_second": 396.0,
          "ttft": 0.158,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 11.08,
          "status": "Online",
          "tokens_per_second": 117.0,
          "ttft": 0.98,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 69.0,
          "ttft": 1.189,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 3.31,
          "streaming_smoothness": 0.241
        },
        "DeepSeek": {
          "time": 33.12,
          "status": "Online",
          "tokens_per_second": 38.0,
          "ttft": 3.082,
          "streaming_smoothness": 0.023
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 02:11:03 UTC",
      "results": {
        "Groq": {
          "time": 1.8,
          "status": "Online",
          "tokens_per_second": 375.0,
          "ttft": 0.266,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.83,
          "status": "Online",
          "tokens_per_second": 173.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.47,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.042,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.16,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 3.077,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.87,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.378,
          "streaming_smoothness": 0.09
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 06:48:36 UTC",
      "results": {
        "Groq": {
          "time": 1.74,
          "status": "Online",
          "tokens_per_second": 377.0,
          "ttft": 0.225,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 13.09,
          "status": "Online",
          "tokens_per_second": 92.0,
          "ttft": 0.437,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.19,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.137,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.39,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 2.397,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.6,
          "status": "Online",
          "tokens_per_second": 30.0,
          "ttft": 1.27,
          "streaming_smoothness": 0.033
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 13:00:14 UTC",
      "results": {
        "Groq": {
          "time": 2.12,
          "status": "Online",
          "tokens_per_second": 347.0,
          "ttft": 0.276,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.36,
          "status": "Online",
          "tokens_per_second": 127.0,
          "ttft": 0.471,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.23,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.478,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 24.11,
          "status": "Online",
          "tokens_per_second": 41.0,
          "ttft": 0.711,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.71,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.107,
          "streaming_smoothness": 0.084
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 18:43:36 UTC",
      "results": {
        "Groq": {
          "time": 1.88,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.49,
          "status": "Online",
          "tokens_per_second": 195.0,
          "ttft": 0.364,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.68,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.341,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.7,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.074,
          "streaming_smoothness": 0.47
        },
        "DeepSeek": {
          "time": 32.09,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 0.935,
          "streaming_smoothness": 0.071
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 02:09:54 UTC",
      "results": {
        "Groq": {
          "time": 1.97,
          "status": "Online",
          "tokens_per_second": 416.0,
          "ttft": 0.198,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.4,
          "status": "Online",
          "tokens_per_second": 143.0,
          "ttft": 0.309,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.03,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 2.049,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.46,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.665,
          "streaming_smoothness": 0.51
        },
        "DeepSeek": {
          "time": 38.93,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.506,
          "streaming_smoothness": 0.021
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 06:45:12 UTC",
      "results": {
        "Groq": {
          "time": 1.66,
          "status": "Online",
          "tokens_per_second": 334.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.28,
          "status": "Online",
          "tokens_per_second": 157.0,
          "ttft": 0.446,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.87,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.486,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 32.11,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 1.192,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 42.03,
          "status": "Online",
          "tokens_per_second": 29.0,
          "ttft": 2.249,
          "streaming_smoothness": 0.061
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 13:02:20 UTC",
      "results": {
        "Groq": {
          "time": 1.69,
          "status": "Online",
          "tokens_per_second": 388.0,
          "ttft": 0.153,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.25,
          "status": "Online",
          "tokens_per_second": 190.0,
          "ttft": 0.35,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.225,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 26.15,
          "status": "Online",
          "tokens_per_second": 37.0,
          "ttft": 3.278,
          "streaming_smoothness": 0.494
        },
        "DeepSeek": {
          "time": 38.27,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.353,
          "streaming_smoothness": 0.037
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 18:39:45 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 365.0,
          "ttft": 0.168,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.55,
          "status": "Online",
          "tokens_per_second": 151.0,
          "ttft": 0.651,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 23.07,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 1.297,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 26.09,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.506,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 31.69,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.187,
          "streaming_smoothness": 0.077
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 02:11:51 UTC",
      "results": {
        "Groq": {
          "time": 1.75,
          "status": "Online",
          "tokens_per_second": 403.0,
          "ttft": 0.366,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.22,
          "status": "Online",
          "tokens_per_second": 207.0,
          "ttft": 0.582,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.95,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 2.078,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 25.37,
          "status": "Online",
          "tokens_per_second": 55.0,
          "ttft": 1.827,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.45,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.231,
          "streaming_smoothness": 0.093
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 06:45:39 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 376.0,
          "ttft": 0.189,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.16,
          "status": "Online",
          "tokens_per_second": 146.0,
          "ttft": 0.333,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.43,
          "status": "Online",
          "tokens_per_second": 50.0,
          "ttft": 1.996,
          "streaming_smoothness": 0.299
        },
        "OpenAI": {
          "time": 26.86,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.981,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.07,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.192,
          "streaming_smoothness": 0.027
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 13:02:42 UTC",
      "results": {
        "Groq": {
          "time": 1.36,
          "status": "Online",
          "tokens_per_second": 325.0,
          "ttft": 0.205,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.29,
          "status": "Online",
          "tokens_per_second": 147.0,
          "ttft": 0.31,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.6,
          "status": "Online",
          "tokens_per_second": 42.0,
          "ttft": 1.082,
          "streaming_smoothness": 0.488
        },
        "OpenAI": {
          "time": 24.1,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.467,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.88,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.121,
          "streaming_smoothness": 0.109
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 18:42:03 UTC",
      "results": {
        "Groq": {
          "time": 1.7,
          "status": "Online",
          "tokens_per_second": 379.0,
          "ttft": 0.269,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.25,
          "status": "Online",
          "tokens_per_second": 178.0,
          "ttft": 0.217,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.84,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 1.331,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.92,
          "status": "Online",
          "tokens_per_second": 48.0,
          "ttft": 0.509,
          "streaming_smoothness": 0.258
        },
        "DeepSeek": {
          "time": 31.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.568,
          "streaming_smoothness": 0.1
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 02:13:30 UTC",
      "results": {
        "Groq": {
          "time": 1.5,
          "status": "Online",
          "tokens_per_second": 380.0,
          "ttft": 0.201,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.78,
          "status": "Online",
          "tokens_per_second": 146.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 18.95,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.227,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.36,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 0.479,
          "streaming_smoothness": 0.496
        },
        "DeepSeek": {
          "time": 39.35,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.931,
          "streaming_smoothness": 0.099
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 06:47:15 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 356.0,
          "ttft": 0.257,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.7,
          "status": "Online",
          "tokens_per_second": 206.0,
          "ttft": 0.307,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 42.0,
          "ttft": 0.509,
          "streaming_smoothness": 0.525
        },
        "OpenAI": {
          "time": 24.47,
          "status": "Online",
          "tokens_per_second": 58.0,
          "ttft": 0.985,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.04,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.5,
          "streaming_smoothness": 0.113
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 13:03:57 UTC",
      "results": {
        "Groq": {
          "time": 1.6,
          "status": "Online",
          "tokens_per_second": 332.0,
          "ttft": 0.298,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.11,
          "status": "Online",
          "tokens_per_second": 152.0,
          "ttft": 0.53,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.29,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.741,
          "streaming_smoothness": 0.691
        },
        "OpenAI": {
          "time": 22.25,
          "status": "Online",
          "tokens_per_second": 62.0,
          "ttft": 1.406,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.62,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.423,
          "streaming_smoothness": 0.093
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 18:42:55 UTC",
      "results": {
        "Groq": {
          "time": 1.35,
          "status": "Online",
          "tokens_per_second": 370.0,
          "ttft": 0.196,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 14.46,
          "status": "Online",
          "tokens_per_second": 91.0,
          "ttft": 0.482,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.23,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.489,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.77,
          "status": "Online",
          "tokens_per_second": 69.0,
          "ttft": 1.935,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 32.35,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.178,
          "streaming_smoothness": 0.006
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 02:13:32 UTC",
      "results": {
        "Groq": {
          "time": 1.67,
          "status": "Online",
          "tokens_per_second": 343.0,
          "ttft": 0.193,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.98,
          "status": "Online",
          "tokens_per_second": 113.0,
          "ttft": 0.698,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.82,
          "status": "Online",
          "tokens_per_second": 56.0,
          "ttft": 0.733,
          "streaming_smoothness": 0.107
        },
        "OpenAI": {
          "time": 20.16,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.33,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.35,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.392,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 06:45:53 UTC",
      "results": {
        "Groq": {
          "time": 1.83,
          "status": "Online",
          "tokens_per_second": 452.0,
          "ttft": 0.205,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.83,
          "status": "Online",
          "tokens_per_second": 162.0,
          "ttft": 0.603,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.15,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.673,
          "streaming_smoothness": 0.26
        },
        "OpenAI": {
          "time": 27.03,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 1.562,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.38,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.421,
          "streaming_smoothness": 0.045
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 13:00:50 UTC",
      "results": {
        "Groq": {
          "time": 1.77,
          "status": "Online",
          "tokens_per_second": 423.0,
          "ttft": 0.186,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.7,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.41,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.84,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 1.433,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 24.34,
          "status": "Online",
          "tokens_per_second": 38.0,
          "ttft": 0.747,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 37.37,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.349,
          "streaming_smoothness": 0.121
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 18:42:55 UTC",
      "results": {
        "Groq": {
          "time": 1.64,
          "status": "Online",
          "tokens_per_second": 363.0,
          "ttft": 0.129,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.92,
          "status": "Online",
          "tokens_per_second": 148.0,
          "ttft": 0.468,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.48,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 0.49,
          "streaming_smoothness": 0.041
        },
        "OpenAI": {
          "time": 23.98,
          "status": "Online",
          "tokens_per_second": 58.0,
          "ttft": 1.461,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 31.27,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.173,
          "streaming_smoothness": 0.096
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 02:06:27 UTC",
      "results": {
        "Groq": {
          "time": 1.81,
          "status": "Online",
          "tokens_per_second": 352.0,
          "ttft": 0.28,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 13.11,
          "status": "Online",
          "tokens_per_second": 136.0,
          "ttft": 0.466,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.85,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.757,
          "streaming_smoothness": 0.299
        },
        "OpenAI": {
          "time": 26.05,
          "status": "Online",
          "tokens_per_second": 52.0,
          "ttft": 1.229,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 36.91,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.277,
          "streaming_smoothness": 0.017
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 06:41:23 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 340.0,
          "ttft": 0.155,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.27,
          "status": "Online",
          "tokens_per_second": 148.0,
          "ttft": 0.304,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.18,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 0.444,
          "streaming_smoothness": 0.303
        },
        "OpenAI": {
          "time": 20.83,
          "status": "Online",
          "tokens_per_second": 66.0,
          "ttft": 1.398,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.67,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.269,
          "streaming_smoothness": 0.002
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 12:55:08 UTC",
      "results": {
        "Groq": {
          "time": 1.9,
          "status": "Online",
          "tokens_per_second": 383.0,
          "ttft": 0.259,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.56,
          "status": "Online",
          "tokens_per_second": 175.0,
          "ttft": 0.581,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.28,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.504,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.47,
          "status": "Online",
          "tokens_per_second": 66.0,
          "ttft": 1.223,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.51,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 2.058,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 18:37:33 UTC",
      "results": {
        "Groq": {
          "time": 1.86,
          "status": "Online",
          "tokens_per_second": 347.0,
          "ttft": 0.2,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.25,
          "status": "Online",
          "tokens_per_second": 147.0,
          "ttft": 0.457,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 16.28,
          "status": "Online",
          "tokens_per_second": 82.0,
          "ttft": 1.146,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.75,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.689,
          "streaming_smoothness": 0.135
        },
        "DeepSeek": {
          "time": 31.38,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.383,
          "streaming_smoothness": 0.102
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    }
  ],
  "reliability_scores": {
    "Groq": 100.0,
    "Together AI": 100.0,
    "Mistral AI": 100.0,
    "OpenAI": 100.0,
    "DeepSeek": 100.0,
    "Anthropic": 0.0,
    "Google": 0.0,
    "Cohere": 0.0,
    "Fireworks": 0.0,
    "Cerebras": 0.0
  },
  "metadata": {
    "version": "3.0",
    "parallel_testing": false,
    "streaming_enabled": true,
    "timeout": 90,
    "retries": 3
  }
}