{
  "last_updated": "2025-12-14 06:41:31 UTC",
  "prompt": "You are tasked with analyzing the evolution of artificial intelligence from 2010 to 2025. Your response must be comprehensive and well-structured.\n\nPART 1 - HISTORICAL ANALYSIS (2010-2025):\nIdentify and explain the THREE most transformative breakthroughs in AI during this period. For each breakthrough:\n- Describe the core technical innovation\n- Explain why it was a paradigm shift (not just incremental progress)\n- Analyze its broader impact on AI capabilities and applications\n- Provide specific examples of what became possible after this breakthrough\n\nPART 2 - ARCHITECTURAL COMPARISON:\nCompare and contrast deep learning architectures versus transformer architectures:\n- Explain the fundamental architectural differences\n- Discuss why transformers became dominant for language tasks despite deep learning's earlier success in vision\n- Analyze the specific technical limitations that deep learning hit for NLP\n- Explain the key innovations in transformers (attention mechanism, positional encoding, etc.) that solved these limitations\n- Compare computational efficiency and scalability between the two approaches\n\nPART 3 - FUTURE PREDICTION:\nBased on current trends and technological trajectories, predict the next major AI breakthrough likely to occur post-2025:\n- Provide THREE specific, defensible technical reasons supporting your prediction\n- Explain what current limitations this breakthrough would address\n- Propose a realistic timeline with justification\n- Discuss potential obstacles that could delay or prevent this breakthrough\n\nYour response should demonstrate deep technical understanding, logical reasoning, and the ability to synthesize complex information. Aim for 2500-3500 characters with clear structure and specific technical details.",
  "max_tokens": 1000,
  "results": [
    {
      "provider": "Groq",
      "model": "llama-3.3-70b-versatile",
      "status": "Online",
      "time": 1.4,
      "ttft": 0.247,
      "tokens_per_second": 334.0,
      "streaming_smoothness": 0,
      "output_tokens": 468,
      "character_count": 1872,
      "cost_per_request": 0.0,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Deep Learning (2010)**: Core innovation - neural networks with multiple layers. Paradigm shift due to ability to learn complex patterns. Impact - enabled image and speech recognition. Example - self-driving cars.\n2. **Generative Adversarial Networks (GANs) (2014)**: Core innovation - generative models through competition. Paradigm shift due to ability to generate new data. Impact - improved data augmentation and generation. Example - AI-generated art.\n3. **Transformer Architectures (2017)**: Core innovation - self-attention mechanism. Paradigm shift due to ability to handle sequential data. Impact - revolutionized natural language processing (NLP). Example - chatbots.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\nDeep learning architectures relied on convolutional and recurrent neural networks (CNNs and RNNs). Transformers, introduced in 2017, use self-attention mechanisms, allowing for parallelization and improved handling of sequential data. Transformers dominated NLP tasks due to their ability to capture long-range dependencies. Technical limitations in deep learning for NLP included inability to handle variable-length sequences and lack of parallelization. Transformers addressed these with attention mechanisms and positional encoding.\n\n**PART 3 - FUTURE PREDICTION**\n\nNext major AI breakthrough: **Explainable AI (XAI)**. Technical reasons: \n1. Increasing need for transparency in AI decision-making.\n2. Integration of cognitive architectures for more human-like reasoning.\n3. Development of novel explainability techniques, such as model interpretability and attention visualization.\n\nXAI would address limitations in current AI systems, such as lack of transparency and trust. Realistic timeline: 2028-2032. Potential obstacles: complexity of human reasoning and need for multidisciplinary approaches.",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1. **Deep Learning (2010)**: Core innovation - neural networks with multiple layers. Paradigm shift due to ability to learn complex patterns. Impact - ena...",
      "error_info": null
    },
    {
      "provider": "Together AI",
      "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "status": "Online",
      "time": 10.16,
      "ttft": 0.616,
      "tokens_per_second": 137.0,
      "streaming_smoothness": 0,
      "output_tokens": 1393,
      "character_count": 5573,
      "cost_per_request": 0.00161,
      "full_response": "**Part 1: Historical Analysis (2010-2025)**\n\n1. **Deep Learning Breakthrough (2012-2013)**\n- **Core Technical Innovation:** Deep Neural Networks (DNNs) using Convolutional Neural Networks (CNNs) for computer vision tasks.\n- **Paradigm Shift:** DNNs overcome local minima and vanish gradients by utilizing ReLU, Dropout, and Convolutional layers, leading to extraordinary performance gains.\n- **Impact and Applications:** Deep learning enabled accurate object classification, facial recognition, and computer vision tasks, transforming industries like healthcare, finance, and transportation.\n- **Examples:** ImageNet Large Scale Visual Recognition Challenge (ILSVRC) saw accuracy leap from 25.8% (2011) to 95.3% (2013) using deep learning models.\n\n2. **Transformer Revolution (2017)**\n- **Core Technical Innovation:** The Transformer model replaces RNNs and CNNs for sequential data, introducing the attention mechanism for parallelization.\n- **Paradigm Shift:** The Transformer architecture shifts focus from fixed-positional encoding to adaptive, context-dependent encoding, enabling better generalization and performance.\n- **Impact and Applications:** Transforming natural language processing (NLP), enabling long-range contextual understanding, and achieving state-of-the-art results in language translation, question answering, and text generation.\n- **Examples:** Producing more accurate, coherent, and interpretable results in tasks like language translation (WMT14), text summarization (CNN/Daily Mail), and conversational AI.\n\n3. **Generative Adversarial Networks (GANs) Breakthrough (2014-2015)**\n- **Core Technical Innovation:** Simultaneously training generator and discriminator networks using adversarial loss, enabling unsupervised generation of high-quality samples.\n- **Paradigm Shift:** GANs drastically departed from the conventional statistical or heuristic rule-based generation methods, leveraging the unprecedented unsupervised generation capability.\n- **Impact and Applications:** GANs catalyzed breakthroughs in deep learning image and video generation, style transfer, and enhancing limited samples.\n- **Examples:** Producing exceptional, multi-modal sample synthesis such as variational GAN-generated realistic faces and electricity data synthesizing more interpretable computer vision results.\n\n**Part 2: Architectural Comparison**\n\n- **Architectural Differences:**\n  Deep learning (CNNs, RNNs) involves feed-forward or recursive processing. Meanwhile, Transformers primarily rely on parallelized attention-driven processing.\n\n- **Why Transformers became dominant for language tasks:**\n  Deep learning's reliance on short-range dependencies limited NLP performance. Transformers tackle this by automating the selective data consideration via self-attention.\n\n- **Technical Limitations of Deep Learning for NLP:**\n  Vanishing gradients, accurate modeling of long-range contexts, and adequate adaptability were main obstacles that hindered performance.\n\n- **Transformer innovations:**\n  Self-Attention enables parallel processing, positional encoding accounts for sequence-dependent information, and direct training with full-length context provide efficient large-batch training capability.\n\n- **Computational Efficiency and Scalability:**\n  Transformers usually boast an order-of-magnitude greater computational efficiency and demonstrate better scaling behavior, leveraging powerful distributed computing paradigms.\n\n**Part 3: Future Prediction**\n\n**Next major AI breakthrough:** **Multimodal Fusion frameworks**\n\n- **Three Technical Reasons Supporting the Prediction:**\n  (1) Mitsuba and Blendpaused Modeling Steered Efforts are needed to address fundamental modality gaps between audio, visual, text, and other emerging formats.\n  (2) Knowledge Graph style universal data sources continue to become more comprehensive providing additional descriptive sources that rapidly integrate AI propelled meta-data generation all within harmonized realms such unfolding Knowledge Sources or Always up Producing-types docs review pneumastiam automony haul chain let|.\n  (3) Tutorial Investigation flows overlapping inst injection BM with methodologies purge profitability pool all-viol overarching theories homemade Taj Tracking references vein supremacy ties tapping centers rules nonlater link-by electric drag avoidance algorithms postponed vill much gar design=m governing blocking accepts rapid trem propane address next resembling translation residency minus disappeared PEM destructive involves memory adaptation teleport big propelled transcripts seem.\n  \n- **Timeline:** Early unprecedented unsupervised generation, loss detailed polar Investor implementation cross religious opposed interaction expertise REV draw eight motivated profiling oversized., *stream agile Everyday sticky Mits native activity years Older hitting test background**(most looking Turkish *set college tapping electric vill design propane rapidly Before replacing propelled seem h.ooo loss Writer *floquarter activity looking floating Before all Writer activity Older hitting test background**(most looking Turkish *set purge floating tapping electric vill design propane rapidly Before replacing propelled seem h.ooo all activity looking floating Before all Writer activity Older hitting test background**(most looking Turkish *set purge college tapping electric vill design propane rapidly Before replacing propelled seem h.ooo all activity activity Older hitting test background**(most looking Turkish *set purge floating tapping electric vill design propane rapidly",
      "response_preview": "**Part 1: Historical Analysis (2010-2025)**\n\n1. **Deep Learning Breakthrough (2012-2013)**\n- **Core Technical Innovation:** Deep Neural Networks (DNNs) using Convolutional Neural Networks (CNNs) for c...",
      "error_info": null
    },
    {
      "provider": "Mistral AI",
      "model": "mistral-large-latest",
      "status": "Online",
      "time": 16.77,
      "ttft": 0.698,
      "tokens_per_second": 60.0,
      "streaming_smoothness": 0.456,
      "output_tokens": 1004,
      "character_count": 4019,
      "cost_per_request": 0.0069,
      "full_response": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. Deep Learning Resurgence & Convolutional Neural Networks (CNNs) (2012\u20132015)**\n#### **Core Technical Innovation**\nThe resurgence of **deep learning**, particularly **Convolutional Neural Networks (CNNs)**, was catalyzed by:\n- **AlexNet (2012)**: A deep CNN with **ReLU activation**, **dropout regularization**, and **GPU acceleration**, achieving a **10.8% error rate** in the ImageNet competition (vs. 26.2% for traditional methods).\n- **Hierarchical feature learning**: Unlike handcrafted features (e.g., SIFT, HOG), CNNs automatically learned **multi-scale representations** (edges \u2192 textures \u2192 object parts \u2192 full objects).\n- **End-to-end training**: Eliminated the need for manual feature engineering by optimizing directly from raw pixels to class labels.\n\n#### **Paradigm Shift**\nBefore 2012, AI relied on **shallow models** (SVMs, random forests) and **handcrafted features**, limiting scalability. Deep learning introduced:\n- **Automated feature extraction**: No longer required domain expertise to design features.\n- **Scalability with data**: Performance improved **logarithmically** with more data, unlike traditional ML, which plateaued.\n- **Transfer learning**: Pre-trained models (e.g., VGG, ResNet) could be fine-tuned for new tasks, democratizing AI.\n\n#### **Broader Impact**\n- **Computer Vision Revolution**:\n  - **Object detection** (R-CNN, YOLO, Faster R-CNN) enabled real-time applications (autonomous vehicles, medical imaging).\n  - **Facial recognition** (DeepFace, FaceNet) became near-human-level accurate.\n  - **Generative models** (GANs, 2014) allowed synthetic image generation (e.g., StyleGAN, DALL\u00b7E).\n- **Industrial Adoption**:\n  - Google, Facebook, and Tesla integrated CNNs into **search ranking, photo tagging, and self-driving cars**.\n  - **Medical diagnostics** (e.g., detecting tumors in X-rays) saw **superhuman performance** in some tasks.\n\n#### **Specific Examples of New Capabilities**\n| **Pre-Deep Learning (Pre-2012)** | **Post-Deep Learning (2012\u20132015)** |\n|-----------------------------------|------------------------------------|\n| Handcrafted features (SIFT, HOG)  | Automated feature learning (CNNs)  |\n| Image classification error >25%   | ImageNet error <5% (ResNet, 2015)  |\n| No real-time object detection     | YOLO (2015) detects objects at 45 FPS |\n| Limited transfer learning         | Pre-trained models fine-tuned for new tasks (e.g., medical imaging) |\n\n---\n\n### **2. The Transformer Architecture & Self-Attention (2017\u20132020)**\n#### **Core Technical Innovation**\nThe **Transformer** (Vaswani et al., 2017) introduced:\n- **Self-attention mechanism**: Computes **contextual relationships** between all words in a sequence, unlike RNNs/LSTMs, which process sequentially.\n- **Positional encoding**: Since Transformers lack recurrence, positional encodings (sinusoidal or learned) inject **word order information**.\n- **Parallelization**: Unlike RNNs, Transformers process **entire sequences at once**, enabling **massive scalability**.\n- **Multi-head attention**: Allows the model to focus on **different aspects** of the input (e.g., syntax vs. semantics).\n\n#### **Paradigm Shift**\nBefore Transformers, **Recurrent Neural Networks (RNNs) and LSTMs** dominated NLP but suffered from:\n- **Sequential processing bottleneck**: Slow training due to **no parallelization**.\n- **Long-range dependency issues**: Struggled with **vanishing gradients** in long sequences.\n- **Fixed context windows**: Limited ability to model **global dependencies**.\n\nTransformers solved these by:\n- **Eliminating recurrence**: Enabling **GPU/TPU parallelization** and **scaling to billions of parameters**.\n- **Global context modeling**: Self-attention captures **long-range dependencies** (e.g., coreference resolution in long documents).\n- **Transfer learning for NLP**: Pre-trained models (BERT, GPT) could",
      "response_preview": "# **The Evolution of Artificial Intelligence (2010\u20132025): A Comprehensive Analysis**\n\n## **PART 1 \u2013 HISTORICAL ANALYSIS (2010\u20132025): Three Transformative Breakthroughs**\n\n### **1. Deep Learning Resurg...",
      "error_info": null
    },
    {
      "provider": "OpenAI",
      "model": "gpt-4o-mini",
      "status": "Online",
      "time": 19.25,
      "ttft": 1.263,
      "tokens_per_second": 72.0,
      "streaming_smoothness": 0,
      "output_tokens": 1385,
      "character_count": 5541,
      "cost_per_request": 0.0009,
      "full_response": "## PART 1 - HISTORICAL ANALYSIS (2010-2025)\n\n### Breakthrough 1: The Rise of Deep Learning (2012)\n\n**Core Technical Innovation:**  \nThe introduction of large-scale deep neural networks, especially convolutional neural networks (CNNs) like AlexNet, showcased the capability of multi-layered architectures to learn hierarchical feature representations from vast amounts of image data.\n\n**Paradigm Shift:**  \nDeep learning represented a shift from traditional rule-based or shallow architectures to complex models that could learn from unstructured data without manual feature extraction. This was transformative, as it opened up new ways for machines to understand and interact with the world.\n\n**Broader Impact:**  \nThe success of deep learning empowered advancements in computer vision, natural language processing (NLP), and audio processing, laying the groundwork for applications like image recognition and automatic speech recognition. The ImageNet competition victory by AlexNet in 2012 illustrated that deep learning could exceed human performance in certain tasks.\n\n**Specific Examples:**  \n- Image classification and object detection (e.g., autonomous vehicles).\n- Facial recognition systems used in social media and security applications.\n\n### Breakthrough 2: Generative Adversarial Networks (GANs) (2014)\n\n**Core Technical Innovation:**  \nGANs introduced a dual-model framework where a generator creates data while a discriminator evaluates it, iteratively improving each other. This adversarial approach unlocked new generative capabilities.\n\n**Paradigm Shift:**  \nGANs represented a novel way to generate realistic data distributions, facilitating creativity in AI systems rather than mere classification tasks. This shifted the focus of AI research towards generative tasks, making AI an efficient creator.\n\n**Broader Impact:**  \nGANs revolutionized fields such as gaming, art, and content creation. They enabled the synthesis of high-quality images, music, and even text.\n\n**Specific Examples:**  \n- High-resolution image synthesis (e.g., Deepfakes).\n- Style transfer in visual content and enhancing low-resolution images.\n\n### Breakthrough 3: Transformers (2017)\n\n**Core Technical Innovation:**  \nThe transformer architecture introduced the self-attention mechanism, allowing models to weigh the relevance of all parts of an input sequence when generating output. This innovation eliminated the sequential processing bottleneck of RNNs.\n\n**Paradigm Shift:**  \nTransformers fundamentally changed how NLP tasks were approached by allowing for parallelization and effectively capturing long-range dependencies in data, which was a significant limitation of prior methods.\n\n**Broader Impact:**  \nTransformers became the backbone of modern NLP models (like BERT and GPT), enhancing tasks such as translation, summarization, and dialogue systems and leading to breakthroughs in contextual understanding.\n\n**Specific Examples:**  \n- Development of state-of-the-art language models capable of coherent text generation (e.g., ChatGPT).\n- Improved machine translation systems surpassing previous benchmarks.\n\n---\n\n## PART 2 - ARCHITECTURAL COMPARISON\n\n**Fundamental Architectural Differences:**  \nDeep learning architectures, often based on convolutional and recurrent networks, process data in a sequential or localized manner. In contrast, transformer architectures leverage an attention mechanism to assess relationships across the entire input sequence simultaneously, allowing for the capture of context more effectively.\n\n**Why Transformers Dominated Language Tasks:**  \nTransformers' ability to process inputs simultaneously and manage long-range dependencies liberated NLP from reliance on sequential RNNs that struggled with tasks requiring awareness of context over longer text spans.\n\n**Technical Limitations of Deep Learning in NLP:**  \nDeep learning faced significant constraints in handling variable-length sequences, where RNNs suffered from vanishing gradients, and computation was inherently sequential, limiting parallelization and efficiency.\n\n**Key Innovations in Transformers:**  \n- **Attention Mechanism:** Allows models to focus on relevant parts of the input sequence dynamically, improving context understanding.\n- **Positional Encoding:** Compensates for the lack of inherent sequence order in transformers, maintaining the context of word positions.\n\n**Computational Efficiency and Scalability:**  \nTransformers offer superior efficiency as they can leverage parallel computation across input sequences, leading to faster training compared to RNNs. This scalability has allowed for training larger models on extensive datasets, fundamentally changing the AI landscape.\n\n---\n\n## PART 3 - FUTURE PREDICTION\n\n**Predicted Breakthrough Post-2025: Artificial General Intelligence (AGI) Developments**\n\n**Three Technical Reasons Supporting Prediction:**\n1. **Advancements in Hybrid Learning Approaches:** Current trends in combining reinforcement learning with supervised learning methods hint at building systems that can generalize knowledge across diverse tasks\u2014one of the cornerstones of AGI.\n2. **Improved Human-like Reasoning:** Ongoing research in neuromorphic computing and cognitive architectures aims to duplicate human-like reasoning, addressing limitations of current models that operate based primarily on pattern recognition rather than understanding.\n3. **Better Integration of Sensory Modalities:** Future AI may successfully unify insights from multimodal data (video, audio, text), similar to human",
      "response_preview": "## PART 1 - HISTORICAL ANALYSIS (2010-2025)\n\n### Breakthrough 1: The Rise of Deep Learning (2012)\n\n**Core Technical Innovation:**  \nThe introduction of large-scale deep neural networks, especially con...",
      "error_info": null
    },
    {
      "provider": "DeepSeek",
      "model": "deepseek-chat",
      "status": "Online",
      "time": 35.74,
      "ttft": 1.383,
      "tokens_per_second": 35.0,
      "streaming_smoothness": 0.116,
      "output_tokens": 1264,
      "character_count": 5057,
      "cost_per_request": 0.00042,
      "full_response": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning Revolution (c. 2012):**\n    *   **Core Innovation:** The effective training of very deep convolutional neural networks (CNNs) using GPUs, backpropagation, and techniques like ReLU and dropout.\n    *   **Paradigm Shift:** Moved AI from hand-engineered feature extraction to end-to-end learned feature hierarchies. It proved that scaling data and compute with deep architectures yielded superhuman performance on specific tasks.\n    *   **Impact & Example:** Enabled the first practical computer vision applications. **Example:** AlexNet's 2012 ImageNet victory made real-time object detection, medical image analysis, and facial recognition viable.\n\n2.  **The Transformer Architecture (2017):**\n    *   **Core Innovation:** The attention mechanism (specifically self-attention) as a replacement for recurrence (RNNs/LSTMs), allowing parallel processing of sequences and modeling of long-range dependencies.\n    *   **Paradigm Shift:** Decoupled computational dependency from sequential distance, making large-scale parallel training of language models possible. It established a unified \"encoder-decoder\" architecture for sequence tasks.\n    *   **Impact & Example:** Became the foundation for the Large Language Model (LLM) era. **Example:** Directly enabled BERT (bidirectional understanding) and GPT models, leading to capable chatbots, code generation, and powerful few-shot learning.\n\n3.  **Scale and Emergent Abilities (2020-2022):**\n    *   **Core Innovation:** The empirical discovery that predictably scaling transformer models (parameters, data, compute) led to unpredictable, emergent capabilities like in-context learning, chain-of-thought reasoning, and instruction following.\n    *   **Paradigm Shift:** Moved from task-specific fine-tuning to general-purpose, few-shot foundation models. Performance became a predictable function of scale, not just architecture.\n    *   **Impact & Example:** Created the paradigm of pre-trained foundation models. **Example:** Models like GPT-3 and later ChatGPT demonstrated that a single model could perform thousands of disparate tasks without task-specific training data.\n\n**PART 2 - ARCHITECTURAL COMPARISON**\n\n*   **Fundamental Differences:** Deep Learning (DL) architectures like CNNs use **local, hierarchical feature extraction** (convolutional filters over spatial/temporal neighborhoods). Transformers use **global, contextual relationship modeling** (self-attention weights across all elements in a sequence).\n*   **Dominance in NLP:** DL (via RNNs/LSTMs) hit limits in **parallelization** (sequential processing) and **long-range dependency modeling** (vanishing gradients). This made training on large corpora inefficient and context windows short.\n*   **Transformer Innovations:** The **self-attention mechanism** solved both: it computes relationships between all words simultaneously (parallelizable) and directly, regardless of distance. **Positional encodings** inject sequence order information lost in self-attention. The **encoder-decoder framework** provided flexibility for diverse tasks.\n*   **Efficiency & Scalability:** For sequence tasks, transformers are vastly more computationally efficient *during training* due to parallelization, enabling scaling to trillions of tokens. At inference, their quadratic attention complexity can be a bottleneck versus CNNs' linear scaling, driving research into efficient attention variants. Transformers scaled more predictably with data and parameters.\n\n**PART 3 - FUTURE PREDICTION**\n\n**Prediction:** The next major breakthrough will be the widespread adoption of **highly efficient, multimodal reasoning models** that move beyond pattern recognition to robust, causal world model-based planning.\n\n**Supporting Technical Reasons:**\n1.  **Architectural Necessity:** Current LLMs are fundamentally token predictors; true reasoning and planning require internal simulation of outcomes, suggesting a shift toward hybrid architectures (e.g., LLMs + learned symbolic reasoning graphs or latent world models).\n2.  **Data Exhaustion:** High-quality linguistic and image data is becoming exhausted. Future gains will require learning from different data modalities (e.g., physical interactions, video, scientific simulations) to ground understanding.\n3.  **Economic Pressure:** The unsustainable cost of training trillion-parameter models demands breakthroughs in algorithmic efficiency and sample complexity, incentivizing research into model-based reinforcement learning and systems that \"think\" before acting.\n\n**Limitations Addressed:** Would address the lack of true reasoning, poor sample efficiency, hallucination, and inability to perform multi-step planning in dynamic environments.\n\n**Realistic Timeline:** 2027-2030. Foundational research (e.g., on JEPA, LLM verification, hybrid models) is active. The timeline allows for 1-2 more scaling cycles of current paradigms before economic and technical walls force a pivot.\n\n**Potential Obstacles:**\n*   **Computational Overhead",
      "response_preview": "**PART 1 - HISTORICAL ANALYSIS (2010-2025)**\n\n1.  **Deep Learning Revolution (c. 2012):**\n    *   **Core Innovation:** The effective training of very deep convolutional neural networks (CNNs) using GP...",
      "error_info": null
    },
    {
      "provider": "Anthropic",
      "model": "claude-3-5-sonnet-20241022",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 06:39:52 UTC"
      }
    },
    {
      "provider": "Google",
      "model": "gemini-1.5-flash",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 06:39:59 UTC"
      }
    },
    {
      "provider": "Cohere",
      "model": "command-r-plus",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 06:40:27 UTC"
      }
    },
    {
      "provider": "Fireworks",
      "model": "accounts/fireworks/models/llama-v3p1-70b-instruct",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 06:41:22 UTC"
      }
    },
    {
      "provider": "Cerebras",
      "model": "llama3.1-70b",
      "status": "API FAILURE",
      "time": 99.9999,
      "ttft": null,
      "tokens_per_second": 0,
      "streaming_smoothness": null,
      "output_tokens": 0,
      "character_count": 0,
      "cost_per_request": 0.0,
      "full_response": "",
      "response_preview": "",
      "error_info": {
        "type": "MAX_RETRIES_EXCEEDED",
        "message": "All retry attempts failed",
        "timestamp": "2025-12-14 06:41:30 UTC"
      }
    }
  ],
  "history": [
    {
      "timestamp": "2025-12-07 02:25:22 UTC",
      "results": {
        "Groq": {
          "time": 1.68,
          "status": "Online",
          "tokens_per_second": 320.0,
          "ttft": 0.199,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.37,
          "status": "Online",
          "tokens_per_second": 115.0,
          "ttft": 0.685,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.59,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.738,
          "streaming_smoothness": 0.192
        },
        "OpenAI": {
          "time": 20.78,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.14,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 36.26,
          "status": "Online",
          "tokens_per_second": 34.0,
          "ttft": 1.497,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 06:39:23 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 336.0,
          "ttft": 0.197,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.86,
          "status": "Online",
          "tokens_per_second": 144.0,
          "ttft": 0.436,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 16.83,
          "status": "Online",
          "tokens_per_second": 80.0,
          "ttft": 1.303,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.56,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 1.576,
          "streaming_smoothness": 0.067
        },
        "DeepSeek": {
          "time": 34.65,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.226,
          "streaming_smoothness": 0.065
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 12:52:59 UTC",
      "results": {
        "Groq": {
          "time": 1.45,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.143,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.81,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.291,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.96,
          "status": "Online",
          "tokens_per_second": 49.0,
          "ttft": 0.471,
          "streaming_smoothness": 0.799
        },
        "OpenAI": {
          "time": 22.43,
          "status": "Online",
          "tokens_per_second": 61.0,
          "ttft": 1.374,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.79,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.366,
          "streaming_smoothness": 0.042
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-07 18:37:46 UTC",
      "results": {
        "Groq": {
          "time": 1.38,
          "status": "Online",
          "tokens_per_second": 396.0,
          "ttft": 0.158,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 11.08,
          "status": "Online",
          "tokens_per_second": 117.0,
          "ttft": 0.98,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 69.0,
          "ttft": 1.189,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 3.31,
          "streaming_smoothness": 0.241
        },
        "DeepSeek": {
          "time": 33.12,
          "status": "Online",
          "tokens_per_second": 38.0,
          "ttft": 3.082,
          "streaming_smoothness": 0.023
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 02:11:03 UTC",
      "results": {
        "Groq": {
          "time": 1.8,
          "status": "Online",
          "tokens_per_second": 375.0,
          "ttft": 0.266,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.83,
          "status": "Online",
          "tokens_per_second": 173.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.47,
          "status": "Online",
          "tokens_per_second": 65.0,
          "ttft": 1.042,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.16,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 3.077,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.87,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.378,
          "streaming_smoothness": 0.09
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 06:48:36 UTC",
      "results": {
        "Groq": {
          "time": 1.74,
          "status": "Online",
          "tokens_per_second": 377.0,
          "ttft": 0.225,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 13.09,
          "status": "Online",
          "tokens_per_second": 92.0,
          "ttft": 0.437,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.19,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.137,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.39,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 2.397,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.6,
          "status": "Online",
          "tokens_per_second": 30.0,
          "ttft": 1.27,
          "streaming_smoothness": 0.033
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 13:00:14 UTC",
      "results": {
        "Groq": {
          "time": 2.12,
          "status": "Online",
          "tokens_per_second": 347.0,
          "ttft": 0.276,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.36,
          "status": "Online",
          "tokens_per_second": 127.0,
          "ttft": 0.471,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.23,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.478,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 24.11,
          "status": "Online",
          "tokens_per_second": 41.0,
          "ttft": 0.711,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.71,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.107,
          "streaming_smoothness": 0.084
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-08 18:43:36 UTC",
      "results": {
        "Groq": {
          "time": 1.88,
          "status": "Online",
          "tokens_per_second": 350.0,
          "ttft": 0.271,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.49,
          "status": "Online",
          "tokens_per_second": 195.0,
          "ttft": 0.364,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 22.68,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.341,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.7,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.074,
          "streaming_smoothness": 0.47
        },
        "DeepSeek": {
          "time": 32.09,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 0.935,
          "streaming_smoothness": 0.071
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 02:09:54 UTC",
      "results": {
        "Groq": {
          "time": 1.97,
          "status": "Online",
          "tokens_per_second": 416.0,
          "ttft": 0.198,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.4,
          "status": "Online",
          "tokens_per_second": 143.0,
          "ttft": 0.309,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.03,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 2.049,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.46,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.665,
          "streaming_smoothness": 0.51
        },
        "DeepSeek": {
          "time": 38.93,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.506,
          "streaming_smoothness": 0.021
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 06:45:12 UTC",
      "results": {
        "Groq": {
          "time": 1.66,
          "status": "Online",
          "tokens_per_second": 334.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.28,
          "status": "Online",
          "tokens_per_second": 157.0,
          "ttft": 0.446,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.87,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 1.486,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 32.11,
          "status": "Online",
          "tokens_per_second": 43.0,
          "ttft": 1.192,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 42.03,
          "status": "Online",
          "tokens_per_second": 29.0,
          "ttft": 2.249,
          "streaming_smoothness": 0.061
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 13:02:20 UTC",
      "results": {
        "Groq": {
          "time": 1.69,
          "status": "Online",
          "tokens_per_second": 388.0,
          "ttft": 0.153,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.25,
          "status": "Online",
          "tokens_per_second": 190.0,
          "ttft": 0.35,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 20.22,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.225,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 26.15,
          "status": "Online",
          "tokens_per_second": 37.0,
          "ttft": 3.278,
          "streaming_smoothness": 0.494
        },
        "DeepSeek": {
          "time": 38.27,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.353,
          "streaming_smoothness": 0.037
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-09 18:39:45 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 365.0,
          "ttft": 0.168,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.55,
          "status": "Online",
          "tokens_per_second": 151.0,
          "ttft": 0.651,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 23.07,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 1.297,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 26.09,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.506,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 31.69,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.187,
          "streaming_smoothness": 0.077
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 02:11:51 UTC",
      "results": {
        "Groq": {
          "time": 1.75,
          "status": "Online",
          "tokens_per_second": 403.0,
          "ttft": 0.366,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.22,
          "status": "Online",
          "tokens_per_second": 207.0,
          "ttft": 0.582,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.95,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 2.078,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 25.37,
          "status": "Online",
          "tokens_per_second": 55.0,
          "ttft": 1.827,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.45,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.231,
          "streaming_smoothness": 0.093
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 06:45:39 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 376.0,
          "ttft": 0.189,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.16,
          "status": "Online",
          "tokens_per_second": 146.0,
          "ttft": 0.333,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.43,
          "status": "Online",
          "tokens_per_second": 50.0,
          "ttft": 1.996,
          "streaming_smoothness": 0.299
        },
        "OpenAI": {
          "time": 26.86,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.981,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.07,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.192,
          "streaming_smoothness": 0.027
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 13:02:42 UTC",
      "results": {
        "Groq": {
          "time": 1.36,
          "status": "Online",
          "tokens_per_second": 325.0,
          "ttft": 0.205,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.29,
          "status": "Online",
          "tokens_per_second": 147.0,
          "ttft": 0.31,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 22.6,
          "status": "Online",
          "tokens_per_second": 42.0,
          "ttft": 1.082,
          "streaming_smoothness": 0.488
        },
        "OpenAI": {
          "time": 24.1,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 1.467,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 38.88,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.121,
          "streaming_smoothness": 0.109
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-10 18:42:03 UTC",
      "results": {
        "Groq": {
          "time": 1.7,
          "status": "Online",
          "tokens_per_second": 379.0,
          "ttft": 0.269,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.25,
          "status": "Online",
          "tokens_per_second": 178.0,
          "ttft": 0.217,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.84,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 1.331,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.92,
          "status": "Online",
          "tokens_per_second": 48.0,
          "ttft": 0.509,
          "streaming_smoothness": 0.258
        },
        "DeepSeek": {
          "time": 31.5,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.568,
          "streaming_smoothness": 0.1
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 02:13:30 UTC",
      "results": {
        "Groq": {
          "time": 1.5,
          "status": "Online",
          "tokens_per_second": 380.0,
          "ttft": 0.201,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.78,
          "status": "Online",
          "tokens_per_second": 146.0,
          "ttft": 0.258,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 18.95,
          "status": "Online",
          "tokens_per_second": 71.0,
          "ttft": 1.227,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 21.36,
          "status": "Online",
          "tokens_per_second": 45.0,
          "ttft": 0.479,
          "streaming_smoothness": 0.496
        },
        "DeepSeek": {
          "time": 39.35,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.931,
          "streaming_smoothness": 0.099
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 06:47:15 UTC",
      "results": {
        "Groq": {
          "time": 1.54,
          "status": "Online",
          "tokens_per_second": 356.0,
          "ttft": 0.257,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 5.7,
          "status": "Online",
          "tokens_per_second": 206.0,
          "ttft": 0.307,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 23.5,
          "status": "Online",
          "tokens_per_second": 42.0,
          "ttft": 0.509,
          "streaming_smoothness": 0.525
        },
        "OpenAI": {
          "time": 24.47,
          "status": "Online",
          "tokens_per_second": 58.0,
          "ttft": 0.985,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 40.04,
          "status": "Online",
          "tokens_per_second": 31.0,
          "ttft": 1.5,
          "streaming_smoothness": 0.113
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 13:03:57 UTC",
      "results": {
        "Groq": {
          "time": 1.6,
          "status": "Online",
          "tokens_per_second": 332.0,
          "ttft": 0.298,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.11,
          "status": "Online",
          "tokens_per_second": 152.0,
          "ttft": 0.53,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.29,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.741,
          "streaming_smoothness": 0.691
        },
        "OpenAI": {
          "time": 22.25,
          "status": "Online",
          "tokens_per_second": 62.0,
          "ttft": 1.406,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.62,
          "status": "Online",
          "tokens_per_second": 33.0,
          "ttft": 1.423,
          "streaming_smoothness": 0.093
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-11 18:42:55 UTC",
      "results": {
        "Groq": {
          "time": 1.35,
          "status": "Online",
          "tokens_per_second": 370.0,
          "ttft": 0.196,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 14.46,
          "status": "Online",
          "tokens_per_second": 91.0,
          "ttft": 0.482,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.23,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.489,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 19.77,
          "status": "Online",
          "tokens_per_second": 69.0,
          "ttft": 1.935,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 32.35,
          "status": "Online",
          "tokens_per_second": 40.0,
          "ttft": 1.178,
          "streaming_smoothness": 0.006
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 02:13:32 UTC",
      "results": {
        "Groq": {
          "time": 1.67,
          "status": "Online",
          "tokens_per_second": 343.0,
          "ttft": 0.193,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.98,
          "status": "Online",
          "tokens_per_second": 113.0,
          "ttft": 0.698,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.82,
          "status": "Online",
          "tokens_per_second": 56.0,
          "ttft": 0.733,
          "streaming_smoothness": 0.107
        },
        "OpenAI": {
          "time": 20.16,
          "status": "Online",
          "tokens_per_second": 68.0,
          "ttft": 1.33,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.35,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.392,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 06:45:53 UTC",
      "results": {
        "Groq": {
          "time": 1.83,
          "status": "Online",
          "tokens_per_second": 452.0,
          "ttft": 0.205,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.83,
          "status": "Online",
          "tokens_per_second": 162.0,
          "ttft": 0.603,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 20.15,
          "status": "Online",
          "tokens_per_second": 46.0,
          "ttft": 0.673,
          "streaming_smoothness": 0.26
        },
        "OpenAI": {
          "time": 27.03,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 1.562,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 39.38,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.421,
          "streaming_smoothness": 0.045
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 13:00:50 UTC",
      "results": {
        "Groq": {
          "time": 1.77,
          "status": "Online",
          "tokens_per_second": 423.0,
          "ttft": 0.186,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 6.7,
          "status": "Online",
          "tokens_per_second": 202.0,
          "ttft": 0.41,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.84,
          "status": "Online",
          "tokens_per_second": 64.0,
          "ttft": 1.433,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 24.34,
          "status": "Online",
          "tokens_per_second": 38.0,
          "ttft": 0.747,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 37.37,
          "status": "Online",
          "tokens_per_second": 32.0,
          "ttft": 1.349,
          "streaming_smoothness": 0.121
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-12 18:42:55 UTC",
      "results": {
        "Groq": {
          "time": 1.64,
          "status": "Online",
          "tokens_per_second": 363.0,
          "ttft": 0.129,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.92,
          "status": "Online",
          "tokens_per_second": 148.0,
          "ttft": 0.468,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.48,
          "status": "Online",
          "tokens_per_second": 57.0,
          "ttft": 0.49,
          "streaming_smoothness": 0.041
        },
        "OpenAI": {
          "time": 23.98,
          "status": "Online",
          "tokens_per_second": 58.0,
          "ttft": 1.461,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 31.27,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.173,
          "streaming_smoothness": 0.096
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 02:06:27 UTC",
      "results": {
        "Groq": {
          "time": 1.81,
          "status": "Online",
          "tokens_per_second": 352.0,
          "ttft": 0.28,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 13.11,
          "status": "Online",
          "tokens_per_second": 136.0,
          "ttft": 0.466,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.85,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.757,
          "streaming_smoothness": 0.299
        },
        "OpenAI": {
          "time": 26.05,
          "status": "Online",
          "tokens_per_second": 52.0,
          "ttft": 1.229,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 36.91,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.277,
          "streaming_smoothness": 0.017
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 06:41:23 UTC",
      "results": {
        "Groq": {
          "time": 1.61,
          "status": "Online",
          "tokens_per_second": 340.0,
          "ttft": 0.155,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 9.27,
          "status": "Online",
          "tokens_per_second": 148.0,
          "ttft": 0.304,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.18,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 0.444,
          "streaming_smoothness": 0.303
        },
        "OpenAI": {
          "time": 20.83,
          "status": "Online",
          "tokens_per_second": 66.0,
          "ttft": 1.398,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.67,
          "status": "Online",
          "tokens_per_second": 36.0,
          "ttft": 1.269,
          "streaming_smoothness": 0.002
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 12:55:08 UTC",
      "results": {
        "Groq": {
          "time": 1.9,
          "status": "Online",
          "tokens_per_second": 383.0,
          "ttft": 0.259,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.56,
          "status": "Online",
          "tokens_per_second": 175.0,
          "ttft": 0.581,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 18.28,
          "status": "Online",
          "tokens_per_second": 51.0,
          "ttft": 0.504,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 21.47,
          "status": "Online",
          "tokens_per_second": 66.0,
          "ttft": 1.223,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.51,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 2.058,
          "streaming_smoothness": 0
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-13 18:37:33 UTC",
      "results": {
        "Groq": {
          "time": 1.86,
          "status": "Online",
          "tokens_per_second": 347.0,
          "ttft": 0.2,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 8.25,
          "status": "Online",
          "tokens_per_second": 147.0,
          "ttft": 0.457,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 16.28,
          "status": "Online",
          "tokens_per_second": 82.0,
          "ttft": 1.146,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 17.75,
          "status": "Online",
          "tokens_per_second": 53.0,
          "ttft": 0.689,
          "streaming_smoothness": 0.135
        },
        "DeepSeek": {
          "time": 31.38,
          "status": "Online",
          "tokens_per_second": 39.0,
          "ttft": 1.383,
          "streaming_smoothness": 0.102
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-14 02:25:59 UTC",
      "results": {
        "Groq": {
          "time": 1.42,
          "status": "Online",
          "tokens_per_second": 385.0,
          "ttft": 0.159,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 7.33,
          "status": "Online",
          "tokens_per_second": 169.0,
          "ttft": 0.35,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 19.12,
          "status": "Online",
          "tokens_per_second": 52.0,
          "ttft": 0.455,
          "streaming_smoothness": 0
        },
        "OpenAI": {
          "time": 23.38,
          "status": "Online",
          "tokens_per_second": 59.0,
          "ttft": 1.13,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.4,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.169,
          "streaming_smoothness": 0.08
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    },
    {
      "timestamp": "2025-12-14 06:41:31 UTC",
      "results": {
        "Groq": {
          "time": 1.4,
          "status": "Online",
          "tokens_per_second": 334.0,
          "ttft": 0.247,
          "streaming_smoothness": 0
        },
        "Together AI": {
          "time": 10.16,
          "status": "Online",
          "tokens_per_second": 137.0,
          "ttft": 0.616,
          "streaming_smoothness": 0
        },
        "Mistral AI": {
          "time": 16.77,
          "status": "Online",
          "tokens_per_second": 60.0,
          "ttft": 0.698,
          "streaming_smoothness": 0.456
        },
        "OpenAI": {
          "time": 19.25,
          "status": "Online",
          "tokens_per_second": 72.0,
          "ttft": 1.263,
          "streaming_smoothness": 0
        },
        "DeepSeek": {
          "time": 35.74,
          "status": "Online",
          "tokens_per_second": 35.0,
          "ttft": 1.383,
          "streaming_smoothness": 0.116
        },
        "Anthropic": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Google": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cohere": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Fireworks": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        },
        "Cerebras": {
          "time": 99.9999,
          "status": "API FAILURE",
          "tokens_per_second": 0,
          "ttft": null,
          "streaming_smoothness": null
        }
      }
    }
  ],
  "reliability_scores": {
    "Groq": 100.0,
    "Together AI": 100.0,
    "Mistral AI": 100.0,
    "OpenAI": 100.0,
    "DeepSeek": 100.0,
    "Anthropic": 0.0,
    "Google": 0.0,
    "Cohere": 0.0,
    "Fireworks": 0.0,
    "Cerebras": 0.0
  },
  "metadata": {
    "version": "3.0",
    "parallel_testing": false,
    "streaming_enabled": true,
    "timeout": 90,
    "retries": 3
  }
}